{"meta":{"title":"HuShengBin’s blog","subtitle":"码渣的个人博客","description":"记录码渣的奋斗史","author":"HuShengBin","url":"https://hsb786.github.io"},"pages":[{"title":"关于我","date":"2018-04-09T10:17:26.000Z","updated":"2018-04-11T04:44:39.874Z","comments":true,"path":"about/index.html","permalink":"https://hsb786.github.io/about/index.html","excerpt":"","text":"1995 天枰座，身高不高 码渣一枚，喜欢敲代码，可惜太笨 常年混迹在知乎、豆瓣、网易云，想做个文艺青年，可惜没那个气质 对科技非常感兴趣，可惜穷 联系方式：786398798@qq.com"},{"title":"categories","date":"2018-04-09T10:17:26.000Z","updated":"2018-04-09T10:17:26.909Z","comments":true,"path":"categories/index.html","permalink":"https://hsb786.github.io/categories/index.html","excerpt":"","text":""},{"title":"tags","date":"2018-04-09T10:16:56.000Z","updated":"2018-04-10T09:27:51.546Z","comments":true,"path":"tags/index.html","permalink":"https://hsb786.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"HashMap","slug":"HashMap","date":"2018-04-12T03:29:30.000Z","updated":"2018-04-12T05:02:27.568Z","comments":true,"path":"2018/04/12/HashMap/","link":"","permalink":"https://hsb786.github.io/2018/04/12/HashMap/","excerpt":"HashMap内部存储结构 HashMap内部存储使用了一个Node数组（默认大小是16），而Node类包含一个类型为Node的next变量，也就是相当于一个链表，所有根据hash值计算的bucket一样的key会存储到同一个链表里（即产生了冲突）。","text":"HashMap内部存储结构 HashMap内部存储使用了一个Node数组（默认大小是16），而Node类包含一个类型为Node的next变量，也就是相当于一个链表，所有根据hash值计算的bucket一样的key会存储到同一个链表里（即产生了冲突）。 基本上都是从别人博客里复制下来的，觉得写的很好，可以直接看底部参考中的网址123456789101112131415161718192021222324252627public class HashMap&lt;K,V&gt; extends AbstractMap&lt;K,V&gt; implements Map&lt;K,V&gt;, Cloneable, Serializable &#123; transient Node&lt;K,V&gt;[] table; transient int size; transient int modCount; static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; // aka 16 static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30; static final float DEFAULT_LOAD_FACTOR = 0.75f; static final int TREEIFY_THRESHOLD = 8; static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final int hash; final K key; V value; Node&lt;K,V&gt; next; ..... &#125; .....&#125; table，一个存放节点(Node[])的数组，是Hashmap的基础设施，所有的节点都存放于此。 size，Hashmap存放的键值对的数目，并不等于table数组的长度，因为可能存在链表和红黑树结构。 modCount，Hashmap的修改次数，是实现fail-fast机制的关键（不清楚fail-fast机制的请看需要注意的一些东西） DEFAULT_INITIAL_CAPACITY，表示默认HashMap数组初始大小为16，并且为了后续的rehash操作的方便，Hashmap的数组大小始终为2的整数次幂，即使你输入一个不是2的整数次幂的值，也会变成最小的大于该值的2的整数次幂。 MAXIMUM_CAPACITY，表示Hashmap数组的最大容量，初始值为2^30。 DEFAULT_LOAD_FACTOR，表示负载因子，当Hashmap的实际容量超过了(设定容量x负载因子)，就触发rehash操作，默认值为0.75。 TREEIFY_THRESHOLD，jkd1.8新增的，如果Hashmap数组元素的链表长度超过这个值，就使用红黑树结构代替链表提高查询效率，默认值为8。 数组内的元素的数据结构继承了Map.Entry，用于存放键值对，另外还包含了hash值和next节点，其中hash值可用于存取节点时来寻址的作用，next节点是实现Hashmap的数组+链表(红黑树)结构的关键。 在继续看Hashmap的内部方法之前，做个大致的总结： Hashmap是用于存放键值对的容器，内部实现是基于数组的，数组中存放的是键值对Node节点，一个Node节点保存了一个键值对信息，同时还保存了next节点，可以形成链表结构(在发生hash冲突的时候)。如果链表长度太长，超过了阀值(默认为8)，那么就自动升级为红黑树结构(高效的平衡查找树)，这样一来，数组元素的节点就成为了红黑树的根节点了。 需要注意的是，在java8中如果hash值相同的key数量大于指定值（默认是8）时使用平衡树来代替链表，这会将get()方法的性能从O(n)提高到O(logn)。 HashMap的自动扩容机制 HashMap内部的Node数组默认的大小是16，假设有100万个元素，那么最好的情况下每个hash桶都有62500个元素，这时get()，put()，remove()等方法效率都会降低。为了解决这个问题，HashMap提供了自动扩容机制，当元素个数达到数组大小*loadFactor(加载因子)后会扩大数组的大小，在默认情况下，数组大小为16，loadFactor为0.75，也就是说当HashMap中的元素超过16*0.75=12时，会把数组大小扩展为2*16=32，并且重新计算每个元素在新数组中的位置。 没扩容前，获取EntryE需要遍历5个元素，扩容之后只需要2次。 put() 对key的hashCode()做hash，然后计算index; 如果没碰撞直接放到bucket里； 如果碰撞了，以链表的形式存在buckets后； 如果碰撞导致链表过长（大于等于TREEIFY_THRESHOLD），就把链表转换成红黑树； 如果节点已经存在就替换old value(保证key的唯一性)； 如果bucket满了(超过load factor*current capacity)，就要resize。 123public V put(K key, V value) &#123; return putVal(hash(key), key, value, false, true);&#125; 如果put()方法添加的键值对的键已经存在于Hashmap中，那么就用新的键值的值替代旧值。再看源码put()调用了hash()方法以及putVal()方法 1234static final int hash(Object key) &#123; int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);&#125; 当输入的key为null时，hash值为0，也就是说Hashmap的key是可以为null的。对比HashTable，HashTable的key直接进行了hashCode，如果key为null时，会抛出异常，所以HashTable的key不可以是null。具体如何得到key的hash值呢？首先调用key自身的hashcode()得到一个hash值h(32位int类型)，然后将h与h右移16位之后的数进行异或，得到最终的hash值。至于为什么这么做，这是前人总结出来的算法可以使得hash值分布更加均匀,尽量减少冲突 123456789101112131415161718192021222324252627282930313233343536373839404142final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); else &#123; Node&lt;K,V&gt; e; K k; if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); else &#123; for (int binCount = 0; ; ++binCount) &#123; if ((e = p.next) == null) &#123; p.next = newNode(hash, key, value, null); if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; &#125; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; &#125; &#125; if (e != null) &#123; // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; &#125; &#125; ++modCount; if (++size &gt; threshold) resize(); afterNodeInsertion(evict); return null;&#125; 通过注释，我们可以知道入参都代表了什么： hash：表示key的hash值 key：待存储的key值 value：待存储的value值 onlyIfAbsent：是否需要替换相同的value值。如果为true，表示不替换已经存在的value evict：如果为false，表示数组是新增模式(暂时不知道啥意思,只在方法的最后出现,但不影响其他逻辑) 首先判断当前HashMap的数组是否为空，如果为空，就调用resize()方法初始化一个长度为16的数组，并且获取到数组的长度n，代码如下： 12if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; 然后，根据数组的长度n-1的值与入参key的hash值按位与运算，算出hash值对应于数组中的位置，从tab中将这个位置上面的内容取出，判断为null时，在这个位置新增一个Node。但是，如果取到了数据，也就是这个hash值对应数组的位置上面已经有了键值对存在。那么，就判断这个Node,也就是p的hash值是否与传入的hash相等，然后接着判断key是否相等。如果判断通过，表示要传入的key-val键值对就是tab[i]位置上面的键值对，直接替换即可，不用管后面是链表还是红黑树。如果不是的话，就将这个新的键值对插入链表或者红黑树种即可。插入键值对分两种情况：如果数组元素是链表时，就将节点新增到列表头部。如果链表的长度大于等于红黑树化的阀值-1，就将链表转成红黑树。如果数组元素是红黑树的话，就直接插入键值对Node即可。12345678910111213141516171819202122232425262728293031if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null);else &#123; Node&lt;K,V&gt; e; K k; if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); else &#123; for (int binCount = 0; ; ++binCount) &#123; if ((e = p.next) == null) &#123; p.next = newNode(hash, key, value, null); if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; &#125; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; &#125; &#125; if (e != null) &#123; // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; &#125;&#125; 最后，将修改次数加一，同时判断当前的键值对数量是否即将超过阀值，如果即将超过，需要进行resize操作。12345++modCount; if (++size &gt; threshold) resize(); afterNodeInsertion(evict); return null; get() bucket里的第一个节点，直接命中； 如果有冲突，则通过key.equals(k)去查找对应的entry; 若为树，则在数中通过key.equals(k)查找，O(logn); 若为链表，则在链表中通过key.equals(k)查找，O(n)。 1234public V get(Object key) &#123; Node&lt;K,V&gt; e; return (e = getNode(hash(key), key)) == null ? null : e.value;&#125; 根据入参的key对象计算出key的hash值，调用getNode()方法，再来看看getNode()方法。12345678910111213141516171819final Node&lt;K,V&gt; getNode(int hash, Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k; if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (first = tab[(n - 1) &amp; hash]) != null) &#123; if (first.hash == hash &amp;&amp; // always check first node ((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))) return first; if ((e = first.next) != null) &#123; if (first instanceof TreeNode) return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); do &#123; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; while ((e = e.next) != null); &#125; &#125; return null;&#125; 通过key的hash值与key对象，来查找key对应的键值对的值，如果查找失败则返回null。如何查找的呢？首先，通过key的hash值计算出对应数组的索引，如果索引到的第一个Node节点的key和hash值与入参相等，直接返回该Node。否则，循环遍历下一个节点(可能是链表也有可能是红黑树)。 resize() 在resize的时候，数组容量还是要保持为2的整数次幂，所以扩容的时候容量会翻倍(原容量乘以2)，那么在resize的时候原来的元素在新数组中要不就维持原索引，要不就从原位置再移动2次幂， 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677final Node&lt;K,V&gt;[] resize() &#123; Node&lt;K,V&gt;[] oldTab = table; //记录原数组的容量 int oldCap = (oldTab == null) ? 0 : oldTab.length; int oldThr = threshold; int newCap, newThr = 0; if (oldCap &gt; 0) &#123; //如果老的数组容量大于0，首先判断是否大于等于HashMap的最大容量。如果true，将阈值设置为Integer的最大值，同时数组容量不变 if (oldCap &gt;= MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return oldTab; &#125; //对数组进行扩容，扩容后的数组容量为原来的两倍；同时阈值也扩容为原来的两倍 else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) newThr = oldThr &lt;&lt; 1; // double threshold &#125; else if (oldThr &gt; 0) // initial capacity was placed in threshold newCap = oldThr; else &#123; // zero initial threshold signifies using defaults newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); &#125; if (newThr == 0) &#123; float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); &#125; threshold = newThr; @SuppressWarnings(&#123;&quot;rawtypes&quot;,&quot;unchecked&quot;&#125;) //定义一个新的容量的数组，同时完成对新数组的赋值 Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; table = newTab; if (oldTab != null) &#123; for (int j = 0; j &lt; oldCap; ++j) &#123; Node&lt;K,V&gt; e; if ((e = oldTab[j]) != null) &#123; oldTab[j] = null; if (e.next == null) newTab[e.hash &amp; (newCap - 1)] = e; else if (e instanceof TreeNode) ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); else &#123; // preserve order Node&lt;K,V&gt; loHead = null, loTail = null; Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; do &#123; next = e.next; if ((e.hash &amp; oldCap) == 0) &#123; if (loTail == null) loHead = e; else loTail.next = e; loTail = e; &#125; else &#123; if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; &#125; &#125; while ((e = next) != null); if (loTail != null) &#123; loTail.next = null; newTab[j] = loHead; &#125; if (hiTail != null) &#123; hiTail.next = null; newTab[j + oldCap] = hiHead; &#125; &#125; &#125; &#125; &#125; return newTab;&#125; 为什么线程不安全 如果多个线程同时使用put方法添加元素，而且假设正好存在两个put的key发生了碰撞(根据hash值计算的bucket一样)，那么根据HashMap的实现，这两个key会添加到数组的同一个位置，这样最终就会发生其中一个线程的put的数据被覆盖。 如果多个线程同时检测到元素个数超过数组大小*loadFactor，这样就会发生多个线程同时对Node数组进行扩容，都在重新计算元素位置以及复制数据，但是最终只有一个线程扩容后的数组会赋给table，也就是说其他线程的都会丢失，并且各自线程put的数据也丢失。 扩容时需要rehash，可能会造成死循环(jdk8已修复) 如何线程安全的使用HashMap Hashtable123456public synchronized V get(Object key) &#123; .....&#125;public synchronized V put(K key, V value) &#123; ......&#125; 效率低，一个线程使用put方法时，另一个线程不但不可以使用put方法，连get方法都不可以。 ConcurrentHashMap （效率高）JUC包中的一个类。ConcurrentHashMap 不仅线程安全而且效率高，因为它包含一个 segment 数组，将数据分段存储，给每一段数据配一把锁，也就是所谓的锁分段技术。 SynchronizedMap调用synchronizedMap()方法后返回一个SynchronizedMap类的对象，而在SynchronizedMap类中使用了synchronized同步关键字来保证对Map的操作是线程安全的 1234567891011121314151617181920212223242526272829303132333435363738394041// synchronizedMap方法public static &lt;K,V&gt; Map&lt;K,V&gt; synchronizedMap(Map&lt;K,V&gt; m) &#123; return new SynchronizedMap&lt;&gt;(m); &#125;// SynchronizedMap类private static class SynchronizedMap&lt;K,V&gt; implements Map&lt;K,V&gt;, Serializable &#123; private static final long serialVersionUID = 1978198479659022715L; private final Map&lt;K,V&gt; m; // Backing Map final Object mutex; // Object on which to synchronize SynchronizedMap(Map&lt;K,V&gt; m) &#123; this.m = Objects.requireNonNull(m); mutex = this; &#125; SynchronizedMap(Map&lt;K,V&gt; m, Object mutex) &#123; this.m = m; this.mutex = mutex; &#125; public int size() &#123; synchronized (mutex) &#123;return m.size();&#125; &#125; public boolean isEmpty() &#123; synchronized (mutex) &#123;return m.isEmpty();&#125; &#125; public boolean containsKey(Object key) &#123; synchronized (mutex) &#123;return m.containsKey(key);&#125; &#125; public boolean containsValue(Object value) &#123; synchronized (mutex) &#123;return m.containsValue(value);&#125; &#125; public V get(Object key) &#123; synchronized (mutex) &#123;return m.get(key);&#125; &#125; public V put(K key, V value) &#123; synchronized (mutex) &#123;return m.put(key, value);&#125; &#125; public V remove(Object key) &#123; synchronized (mutex) &#123;return m.remove(key);&#125; &#125; // 省略其他方法 &#125; 从源码中可以看出调用 synchronizedMap() 方法后会返回一个 SynchronizedMap 类的对象，而在 SynchronizedMap 类中使用了 synchronized 同步关键字来保证对 Map 的操作是线程安全的。 总结 HashMap在处理冲突时使用链表存储相同索引的元素。 从Java 8开始，HashMap，ConcurrentHashMap和LinkedHashMap在处理频繁冲突时将使用平衡树来代替链表，当同一hash桶中的元素数量超过特定的值便会由链表切换到平衡树，这会将get()方法的性能从O(n)提高到O(logn)。 当从链表切换到平衡树时，HashMap迭代的顺序将会改变。不过这并不会造成什么问题，因为HashMap并没有对迭代的顺序提供任何保证。 从Java 1中就存在的Hashtable类为了保证迭代顺序不变，即便在频繁冲突的情况下也不会使用平衡树。这一决定是为了不破坏某些较老的需要依赖于Hashtable迭代顺序的Java应用。 除了Hashtable之外，WeakHashMap和IdentityHashMap也不会在频繁冲突的情况下使用平衡树。 使用HashMap之所以会产生冲突是因为使用了键对象的hashCode()方法，而equals()和hashCode()方法不保证不同对象的hashCode是不同的。需要记住的是，相同对象的hashCode一定是相同的，但相同的hashCode不一定是相同的对象。 在HashTable和HashMap中，冲突的产生是由于不同对象的hashCode()方法返回了一样的值。 参考 Java 8中HashMap和LinkedHashMap如何解决冲突 如何线程安全的使用 HashMap 看看HashMap源码","categories":[],"tags":[{"name":"爪哇","slug":"爪哇","permalink":"https://hsb786.github.io/tags/爪哇/"}]},{"title":"String与StringBuffer","slug":"String与StringBuffer","date":"2018-04-11T06:17:41.000Z","updated":"2018-04-11T06:50:46.678Z","comments":true,"path":"2018/04/11/String与StringBuffer/","link":"","permalink":"https://hsb786.github.io/2018/04/11/String与StringBuffer/","excerpt":"String不可变，StringBuffer可变，why ?","text":"String不可变，StringBuffer可变，why ? 看源码 String1234public final class String implements java.io.Serializable, Comparable&lt;String&gt;, CharSequence &#123; /** The value is used for character storage. */ private final char value[]; 可以看出String底层是用char数组实现的，由于被final修饰所以引用不能改变。 为什么要这样设计 只有当字符串是不可变的，字符串池才有可能实现。字符串池的实现可以在运行时节约很多heap空间，因为不同的字符串变量都指向池中的同一个字符串。但如果字符串是可变的，那么String interning将不能实现(String interning是指对不同的字符串仅仅只保存一个，即不会保存多个相同的字符串)，因为这样的话，如果变量改变了它的值，那么其它指向这个值的变量的值也会一起改变。 如果字符串是可变的，那么会引起很严重的安全问题。譬如，数据库的用户名、密码都是以字符串的形式传入来获得数据库的连接，或者在socket编程中，主机名和端口都是以字符串的形式传入。 因为字符串是不可变的，所以它的值是不可改变的，否则黑客们可以钻到空子，改变字符串指向的对象的值，造成安全漏洞。因为字符串是不可变的，所以是多线程安全的，同一个字符串实例可以被多个线程共享。这样便不用因为线程安全问题而使用同步。字符串自己便是线程安全的。 类加载器要用到字符串，不可变性提供了安全性，以便正确的类被加载。譬如你想加载java.sql.Connection类，而这个值被改成了myhacked.Connection，那么会对你的数据库造成不可知的破坏。 因为字符串是不可变的，所以在它创建的时候hashcode就被缓存了，不需要重新计算。这就使得字符串很适合作为Map中的键，字符串的处理速度要快过其它的键对象。这就是HashMap中的键往往都使用字符串。 StringBuffer 12345678910111213141516171819202122232425262728293031323334353637383940414243 public final class StringBuffer extends AbstractStringBuilder implements java.io.Serializable, CharSequence&#123; /** * A cache of the last value returned by toString. Cleared * whenever the StringBuffer is modified. */ private transient char[] toStringCache; @Override public synchronized StringBuffer append(String str) &#123; toStringCache = null; super.append(str); return this; &#125; //AbstractStringBuilder中的方法 public AbstractStringBuilder append(String str) &#123; if (str == null) return appendNull(); int len = str.length(); ensureCapacityInternal(count + len); str.getChars(0, len, value, count); count += len; return this; &#125; //String中的方法 public void getChars(int srcBegin, int srcEnd, char dst[], int dstBegin) &#123; if (srcBegin &lt; 0) &#123; throw new StringIndexOutOfBoundsException(srcBegin); &#125; if (srcEnd &gt; value.length) &#123; throw new StringIndexOutOfBoundsException(srcEnd); &#125; if (srcBegin &gt; srcEnd) &#123; throw new StringIndexOutOfBoundsException(srcEnd - srcBegin); &#125; System.arraycopy(value, srcBegin, dst, dstBegin, srcEnd - srcBegin); &#125; StringBuffer中append中的实现 调用super.append(str)， super类为AbstractStringBuilder AbstractStringBuilder.append(str)中通过调用String类的getChars()方法 String.getChars()，调用System.arraycopy()完成数组的复制 12345678* @param src the source array. * @param srcPos starting position in the source array. * @param dest the destination array. * @param destPos starting position in the destination data. * @param length the number of array elements to be copied. public static native void arraycopy(Object src, int srcPos, Object dest, int destPos, int length); 本地方法的实现。 src原数组，srcPoc原数组起始位；dest目标数组，destPos目标数组起始位,length复制个数 1234 int[] int1= &#123;1,2,3,4&#125;;int[] int2= &#123;10,11,12,13,14,15,16,17&#125;;System.arraycopy(int1, 0, int2, 0, 3); System.out.println(Arrays.toString(int2)); //out [1, 2, 3, 13, 14, 15, 16, 17] 参考 [如何理解 String 类型值的不可变？][https://www.zhihu.com/question/20618891/answer/147575525]","categories":[],"tags":[{"name":"爪哇","slug":"爪哇","permalink":"https://hsb786.github.io/tags/爪哇/"}]},{"title":"工具网站","slug":"工具网站","date":"2018-04-11T04:22:11.000Z","updated":"2018-04-11T04:50:18.850Z","comments":true,"path":"2018/04/11/工具网站/","link":"","permalink":"https://hsb786.github.io/2018/04/11/工具网站/","excerpt":"","text":"图标 在线编码转换 HTTP状态码 Sql转Class","categories":[],"tags":[{"name":"工具","slug":"工具","permalink":"https://hsb786.github.io/tags/工具/"}]},{"title":"HTTP状态码","slug":"HTTP状态码","date":"2018-04-10T12:27:44.000Z","updated":"2018-04-11T04:16:31.866Z","comments":true,"path":"2018/04/10/HTTP状态码/","link":"","permalink":"https://hsb786.github.io/2018/04/10/HTTP状态码/","excerpt":"HTTP状态码（HTTP Status Code）是用以表示网页服务器HTTP响应状态的3位数字代码。它由 RFC 2616 规范定义的，并得到RFC 2518、RFC 2817、RFC 2295、RFC 2774、RFC 4918等规范扩展。","text":"HTTP状态码（HTTP Status Code）是用以表示网页服务器HTTP响应状态的3位数字代码。它由 RFC 2616 规范定义的，并得到RFC 2518、RFC 2817、RFC 2295、RFC 2774、RFC 4918等规范扩展。 status 含义 100 客户端应当继续发送请求。这个临时响应是用来通知客户端它的部分请求已经被服务器接收，且仍未被拒绝。客户端应当继续发送请求的剩余部分，或者如果请求已经完成，忽略这个响应。服务器必须在请求完成后向客户端发送一个最终响应。 101 服务器已经理解了客户端的请求，并将通过Upgrade 消息头通知客户端采用不同的协议来完成这个请求。在发送完这个响应最后的空行后，服务器将会切换到在Upgrade 消息头中定义的那些协议。 只有在切换新的协议更有好处的时候才应该采取类似措施。例如，切换到新的HTTP 版本比旧版本更有优势，或者切换到一个实时且同步的协议以传送利用此类特性的资源。 102 由WebDAV（RFC 2518）扩展的状态码，代表处理将被继续执行。 200 请求已成功，请求所希望的响应头或数据体将随此响应返回。 201 请求已经被实现，而且有一个新的资源已经依据请求的需要而建立，且其 URI 已经随Location 头信息返回。假如需要的资源无法及时建立的话，应当返回 ‘202 Accepted’。 202 服务器已接受请求，但尚未处理。正如它可能被拒绝一样，最终该请求可能会也可能不会被执行。在异步操作的场合下，没有比发送这个状态码更方便的做法了。 返回202状态码的响应的目的是允许服务器接受其他过程的请求（例如某个每天只执行一次的基于批处理的操作），而不必让客户端一直保持与服务器的连接直到批处理操作全部完成。在接受请求处理并返回202状态码的响应应当在返回的实体中包含一些指示处理当前状态的信息，以及指向处理状态监视器或状态预测的指针，以便用户能够估计操作是否已经完成。 203 服务器已成功处理了请求，但返回的实体头部元信息不是在原始服务器上有效的确定集合，而是来自本地或者第三方的拷贝。当前的信息可能是原始版本的子集或者超集。例如，包含资源的元数据可能导致原始服务器知道元信息的超级。使用此状态码不是必须的，而且只有在响应不使用此状态码便会返回200 OK的情况下才是合适的。 204 服务器成功处理了请求，但不需要返回任何实体内容，并且希望返回更新了的元信息。响应可能通过实体头部的形式，返回新的或更新后的元信息。如果存在这些头部信息，则应当与所请求的变量相呼应。 如果客户端是浏览器的话，那么用户浏览器应保留发送了该请求的页面，而不产生任何文档视图上的变化，即使按照规范新的或更新后的元信息应当被应用到用户浏览器活动视图中的文档。 由于204响应被禁止包含任何消息体，因此它始终以消息头后的第一个空行结尾。 205 服务器成功处理了请求，且没有返回任何内容。但是与204响应不同，返回此状态码的响应要求请求者重置文档视图。该响应主要是被用于接受用户输入后，立即重置表单，以便用户能够轻松地开始另一次输入。 与204响应一样，该响应也被禁止包含任何消息体，且以消息头后的第一个空行结束。 206 服务器已经成功处理了部分 GET 请求。类似于 FlashGet 或者迅雷这类的 HTTP 下载工具都是使用此类响应实现断点续传或者将一个大文档分解为多个下载段同时下载。 该请求必须包含 Range 头信息来指示客户端希望得到的内容范围，并且可能包含 If-Range 来作为请求条件。 响应必须包含如下的头部域： Content-Range 用以指示本次响应中返回的内容的范围；如果是 Content-Type 为 multipart/byteranges 的多段下载，则每一 multipart 段中都应包含 Content-Range 域用以指示本段的内容范围。假如响应中包含 Content-Length，那么它的数值必须匹配它返回的内容范围的真实字节数。 Date ETag 和/或 Content-Location，假如同样的请求本应该返回200响应。 Expires, Cache-Control，和/或 Vary，假如其值可能与之前相同变量的其他响应对应的值不同的话。 假如本响应请求使用了 If-Range 强缓存验证，那么本次响应不应该包含其他实体头；假如本响应的请求使用了 If-Range 弱缓存验证，那么本次响应禁止包含其他实体头；这避免了缓存的实体内容和更新了的实体头信息之间的不一致。否则，本响应就应当包含所有本应该返回200响应中应当返回的所有实体头部域。 假如 ETag 或 Last-Modified 头部不能精确匹配的话，则客户端缓存应禁止将206响应返回的内容与之前任何缓存过的内容组合在一起。 任何不支持 Range 以及 Content-Range 头的缓存都禁止缓存206响应返回的内容。 207 由WebDAV(RFC 2518)扩展的状态码，代表之后的消息体将是一个XML消息，并且可能依照之前子请求数量的不同，包含一系列独立的响应代码。 300 被请求的资源有一系列可供选择的回馈信息，每个都有自己特定的地址和浏览器驱动的商议信息。用户或浏览器能够自行选择一个首选的地址进行重定向。 除非这是一个 HEAD 请求，否则该响应应当包括一个资源特性及地址的列表的实体，以便用户或浏览器从中选择最合适的重定向地址。这个实体的格式由 Content-Type 定义的格式所决定。浏览器可能根据响应的格式以及浏览器自身能力，自动作出最合适的选择。当然，RFC 2616规范并没有规定这样的自动选择该如何进行。 如果服务器本身已经有了首选的回馈选择，那么在 Location 中应当指明这个回馈的 URI；浏览器可能会将这个 Location 值作为自动重定向的地址。此外，除非额外指定，否则这个响应也是可缓存的。 301 被请求的资源已永久移动到新位置，并且将来任何对此资源的引用都应该使用本响应返回的若干个 URI 之一。如果可能，拥有链接编辑功能的客户端应当自动把请求的地址修改为从服务器反馈回来的地址。除非额外指定，否则这个响应也是可缓存的。 新的永久性的 URI 应当在响应的 Location 域中返回。除非这是一个 HEAD 请求，否则响应的实体中应当包含指向新的 URI 的超链接及简短说明。 如果这不是一个 GET 或者 HEAD 请求，因此浏览器禁止自动进行重定向，除非得到用户的确认，因为请求的条件可能因此发生变化。 注意：对于某些使用 HTTP/1.0 协议的浏览器，当它们发送的 POST 请求得到了一个301响应的话，接下来的重定向请求将会变成 GET 方式。 302 请求的资源现在临时从不同的 URI 响应请求。由于这样的重定向是临时的，客户端应当继续向原有地址发送以后的请求。只有在Cache-Control或Expires中进行了指定的情况下，这个响应才是可缓存的。 新的临时性的 URI 应当在响应的 Location 域中返回。除非这是一个 HEAD 请求，否则响应的实体中应当包含指向新的 URI 的超链接及简短说明。 如果这不是一个 GET 或者 HEAD 请求，那么浏览器禁止自动进行重定向，除非得到用户的确认，因为请求的条件可能因此发生变化。 注意：虽然RFC 1945和RFC 2068规范不允许客户端在重定向时改变请求的方法，但是很多现存的浏览器将302响应视作为303响应，并且使用 GET 方式访问在 Location 中规定的 URI，而无视原先请求的方法。状态码303和307被添加了进来，用以明确服务器期待客户端进行何种反应。 303 对应当前请求的响应可以在另一个 URI 上被找到，而且客户端应当采用 GET 的方式访问那个资源。这个方法的存在主要是为了允许由脚本激活的POST请求输出重定向到一个新的资源。这个新的 URI 不是原始资源的替代引用。同时，303响应禁止被缓存。当然，第二个请求（重定向）可能被缓存。 新的 URI 应当在响应的 Location 域中返回。除非这是一个 HEAD 请求，否则响应的实体中应当包含指向新的 URI 的超链接及简短说明。 注意：许多 HTTP/1.1 版以前的 浏览器不能正确理解303状态。如果需要考虑与这些浏览器之间的互动，302状态码应该可以胜任，因为大多数的浏览器处理302响应时的方式恰恰就是上述规范要求客户端处理303响应时应当做的。 304 如果客户端发送了一个带条件的 GET 请求且该请求已被允许，而文档的内容（自上次访问以来或者根据请求的条件）并没有改变，则服务器应当返回这个状态码。304响应禁止包含消息体，因此始终以消息头后的第一个空行结尾。 该响应必须包含以下的头信息： Date，除非这个服务器没有时钟。假如没有时钟的服务器也遵守这些规则，那么代理服务器以及客户端可以自行将 Date 字段添加到接收到的响应头中去（正如RFC 2068中规定的一样），缓存机制将会正常工作。 ETag 和/或 Content-Location，假如同样的请求本应返回200响应。 Expires, Cache-Control，和/或Vary，假如其值可能与之前相同变量的其他响应对应的值不同的话。 假如本响应请求使用了强缓存验证，那么本次响应不应该包含其他实体头；否则（例如，某个带条件的 GET 请求使用了弱缓存验证），本次响应禁止包含其他实体头；这避免了缓存了的实体内容和更新了的实体头信息之间的不一致。 假如某个304响应指明了当前某个实体没有缓存，那么缓存系统必须忽视这个响应，并且重复发送不包含限制条件的请求。 假如接收到一个要求更新某个缓存条目的304响应，那么缓存系统必须更新整个条目以反映所有在响应中被更新的字段的值。 305 被请求的资源必须通过指定的代理才能被访问。Location 域中将给出指定的代理所在的 URI 信息，接收者需要重复发送一个单独的请求，通过这个代理才能访问相应资源。只有原始服务器才能建立305响应。 注意：RFC 2068中没有明确305响应是为了重定向一个单独的请求，而且只能被原始服务器建立。忽视这些限制可能导致严重的安全后果。 306 在最新版的规范中，306状态码已经不再被使用。 307 请求的资源现在临时从不同的URI 响应请求。由于这样的重定向是临时的，客户端应当继续向原有地址发送以后的请求。只有在Cache-Control或Expires中进行了指定的情况下，这个响应才是可缓存的。 新的临时性的URI 应当在响应的 Location 域中返回。除非这是一个HEAD 请求，否则响应的实体中应当包含指向新的URI 的超链接及简短说明。因为部分浏览器不能识别307响应，因此需要添加上述必要信息以便用户能够理解并向新的 URI 发出访问请求。 如果这不是一个GET 或者 HEAD 请求，那么浏览器禁止自动进行重定向，除非得到用户的确认，因为请求的条件可能因此发生变化。 400 1、语义有误，当前请求无法被服务器理解。除非进行修改，否则客户端不应该重复提交这个请求。 2、请求参数有误。 401 当前请求需要用户验证。该响应必须包含一个适用于被请求资源的 WWW-Authenticate 信息头用以询问用户信息。客户端可以重复提交一个包含恰当的 Authorization 头信息的请求。如果当前请求已经包含了 Authorization 证书，那么401响应代表着服务器验证已经拒绝了那些证书。如果401响应包含了与前一个响应相同的身份验证询问，且浏览器已经至少尝试了一次验证，那么浏览器应当向用户展示响应中包含的实体信息，因为这个实体信息中可能包含了相关诊断信息。参见RFC 2617。 402 该状态码是为了将来可能的需求而预留的。 403 服务器已经理解请求，但是拒绝执行它。与401响应不同的是，身份验证并不能提供任何帮助，而且这个请求也不应该被重复提交。如果这不是一个 HEAD 请求，而且服务器希望能够讲清楚为何请求不能被执行，那么就应该在实体内描述拒绝的原因。当然服务器也可以返回一个404响应，假如它不希望让客户端获得任何信息。 404 请求失败，请求所希望得到的资源未被在服务器上发现。没有信息能够告诉用户这个状况到底是暂时的还是永久的。假如服务器知道情况的话，应当使用410状态码来告知旧资源因为某些内部的配置机制问题，已经永久的不可用，而且没有任何可以跳转的地址。404这个状态码被广泛应用于当服务器不想揭示到底为何请求被拒绝或者没有其他适合的响应可用的情况下。 405 请求行中指定的请求方法不能被用于请求相应的资源。该响应必须返回一个Allow 头信息用以表示出当前资源能够接受的请求方法的列表。 鉴于 PUT，DELETE 方法会对服务器上的资源进行写操作，因而绝大部分的网页服务器都不支持或者在默认配置下不允许上述请求方法，对于此类请求均会返回405错误。 406 请求的资源的内容特性无法满足请求头中的条件，因而无法生成响应实体。 除非这是一个 HEAD 请求，否则该响应就应当返回一个包含可以让用户或者浏览器从中选择最合适的实体特性以及地址列表的实体。实体的格式由 Content-Type 头中定义的媒体类型决定。浏览器可以根据格式及自身能力自行作出最佳选择。但是，规范中并没有定义任何作出此类自动选择的标准。 407 与401响应类似，只不过客户端必须在代理服务器上进行身份验证。代理服务器必须返回一个 Proxy-Authenticate 用以进行身份询问。客户端可以返回一个 Proxy-Authorization 信息头用以验证。参见RFC 2617。 408 请求超时。客户端没有在服务器预备等待的时间内完成一个请求的发送。客户端可以随时再次提交这一请求而无需进行任何更改。 409 由于和被请求的资源的当前状态之间存在冲突，请求无法完成。这个代码只允许用在这样的情况下才能被使用：用户被认为能够解决冲突，并且会重新提交新的请求。该响应应当包含足够的信息以便用户发现冲突的源头。 冲突通常发生于对 PUT 请求的处理中。例如，在采用版本检查的环境下，某次 PUT 提交的对特定资源的修改请求所附带的版本信息与之前的某个（第三方）请求向冲突，那么此时服务器就应该返回一个409错误，告知用户请求无法完成。此时，响应实体中很可能会包含两个冲突版本之间的差异比较，以便用户重新提交归并以后的新版本。 410 被请求的资源在服务器上已经不再可用，而且没有任何已知的转发地址。这样的状况应当被认为是永久性的。如果可能，拥有链接编辑功能的客户端应当在获得用户许可后删除所有指向这个地址的引用。如果服务器不知道或者无法确定这个状况是否是永久的，那么就应该使用404状态码。除非额外说明，否则这个响应是可缓存的。 410响应的目的主要是帮助网站管理员维护网站，通知用户该资源已经不再可用，并且服务器拥有者希望所有指向这个资源的远端连接也被删除。这类事件在限时、增值服务中很普遍。同样，410响应也被用于通知客户端在当前服务器站点上，原本属于某个个人的资源已经不再可用。当然，是否需要把所有永久不可用的资源标记为’410 Gone’，以及是否需要保持此标记多长时间，完全取决于服务器拥有者。 411 服务器拒绝在没有定义 Content-Length 头的情况下接受请求。在添加了表明请求消息体长度的有效 Content-Length 头之后，客户端可以再次提交该请求。 412 服务器在验证在请求的头字段中给出先决条件时，没能满足其中的一个或多个。这个状态码允许客户端在获取资源时在请求的元信息（请求头字段数据）中设置先决条件，以此避免该请求方法被应用到其希望的内容以外的资源上。 413 服务器拒绝处理当前请求，因为该请求提交的实体数据大小超过了服务器愿意或者能够处理的范围。此种情况下，服务器可以关闭连接以免客户端继续发送此请求。 如果这个状况是临时的，服务器应当返回一个 Retry-After 的响应头，以告知客户端可以在多少时间以后重新尝试。 414 请求的URI 长度超过了服务器能够解释的长度，因此服务器拒绝对该请求提供服务。这比较少见，通常的情况包括： 本应使用POST方法的表单提交变成了GET方法，导致查询字符串（Query String）过长。 重定向URI “黑洞”，例如每次重定向把旧的 URI 作为新的 URI 的一部分，导致在若干次重定向后 URI 超长。 客户端正在尝试利用某些服务器中存在的安全漏洞攻击服务器。这类服务器使用固定长度的缓冲读取或操作请求的 URI，当 GET 后的参数超过某个数值后，可能会产生缓冲区溢出，导致任意代码被执行[1]。没有此类漏洞的服务器，应当返回414状态码。 415 对于当前请求的方法和所请求的资源，请求中提交的实体并不是服务器中所支持的格式，因此请求被拒绝。 416 如果请求中包含了 Range 请求头，并且 Range 中指定的任何数据范围都与当前资源的可用范围不重合，同时请求中又没有定义 If-Range 请求头，那么服务器就应当返回416状态码。 假如 Range 使用的是字节范围，那么这种情况就是指请求指定的所有数据范围的首字节位置都超过了当前资源的长度。服务器也应当在返回416状态码的同时，包含一个 Content-Range 实体头，用以指明当前资源的长度。这个响应也被禁止使用 multipart/byteranges 作为其 Content-Type。 417 在请求头 Expect 中指定的预期内容无法被服务器满足，或者这个服务器是一个代理服务器，它有明显的证据证明在当前路由的下一个节点上，Expect 的内容无法被满足。 421 从当前客户端所在的IP地址到服务器的连接数超过了服务器许可的最大范围。通常，这里的IP地址指的是从服务器上看到的客户端地址（比如用户的网关或者代理服务器地址）。在这种情况下，连接数的计算可能涉及到不止一个终端用户。 422 从当前客户端所在的IP地址到服务器的连接数超过了服务器许可的最大范围。通常，这里的IP地址指的是从服务器上看到的客户端地址（比如用户的网关或者代理服务器地址）。在这种情况下，连接数的计算可能涉及到不止一个终端用户。 422 请求格式正确，但是由于含有语义错误，无法响应。（RFC 4918 WebDAV）423 Locked 当前资源被锁定。（RFC 4918 WebDAV） 424 由于之前的某个请求发生的错误，导致当前请求失败，例如 PROPPATCH。（RFC 4918 WebDAV） 425 在WebDav Advanced Collections 草案中定义，但是未出现在《WebDAV 顺序集协议》（RFC 3658）中。 426 客户端应当切换到TLS/1.0。（RFC 2817） 449 由微软扩展，代表请求应当在执行完适当的操作后进行重试。 500 服务器遇到了一个未曾预料的状况，导致了它无法完成对请求的处理。一般来说，这个问题都会在服务器的程序码出错时出现。 501 服务器不支持当前请求所需要的某个功能。当服务器无法识别请求的方法，并且无法支持其对任何资源的请求。 502 作为网关或者代理工作的服务器尝试执行请求时，从上游服务器接收到无效的响应。 503 由于临时的服务器维护或者过载，服务器当前无法处理请求。这个状况是临时的，并且将在一段时间以后恢复。如果能够预计延迟时间，那么响应中可以包含一个 Retry-After 头用以标明这个延迟时间。如果没有给出这个 Retry-After 信息，那么客户端应当以处理500响应的方式处理它。 注意：503状态码的存在并不意味着服务器在过载的时候必须使用它。某些服务器只不过是希望拒绝客户端的连接。 504 作为网关或者代理工作的服务器尝试执行请求时，未能及时从上游服务器（URI标识出的服务器，例如HTTP、FTP、LDAP）或者辅助服务器（例如DNS）收到响应。 注意：某些代理服务器在DNS查询超时时会返回400或者500错误 505 服务器不支持，或者拒绝支持在请求中使用的 HTTP 版本。这暗示着服务器不能或不愿使用与客户端相同的版本。响应中应当包含一个描述了为何版本不被支持以及服务器支持哪些协议的实体。 506 由《透明内容协商协议》（RFC 2295）扩展，代表服务器存在内部配置错误：被请求的协商变元资源被配置为在透明内容协商中使用自己，因此在一个协商处理中不是一个合适的重点。 507 服务器无法存储完成请求所必须的内容。这个状况被认为是临时的。WebDAV (RFC 4918) 509 服务器达到带宽限制。这不是一个官方的状态码，但是仍被广泛使用。 510 获取资源所需要的策略并没有没满足。（RFC 2774）","categories":[],"tags":[{"name":"HTTP","slug":"HTTP","permalink":"https://hsb786.github.io/tags/HTTP/"}]},{"title":"反转链表","slug":"反转链表","date":"2018-04-10T12:14:31.000Z","updated":"2018-04-11T04:14:05.511Z","comments":true,"path":"2018/04/10/反转链表/","link":"","permalink":"https://hsb786.github.io/2018/04/10/反转链表/","excerpt":"定义一个函数，输入一个链表的头结点，反转该链表并输出反转后的链表的头结点。","text":"定义一个函数，输入一个链表的头结点，反转该链表并输出反转后的链表的头结点。 1234567891011121314151617181920212223242526272829303132333435363738 /** * 维护两个节点，一个指向当前节点，一个指向下一个节点 * 缺点，需要new 对象，占用内存 * @author: husb * @date: 2018年4月10日 下午7:44:22 */private static ListNode reverseList(ListNode head) &#123; ListNode result = new ListNode(head.data); ListNode t; while (head.next != null) &#123; t = result; result = new ListNode(head.next.data); result.next = t; head = head.next; &#125; return result;&#125;/** * @Description: 需要维护三个节点，当前，前一个，下一个 * @author: husb * @date: 2018年4月10日 下午7:57:58 */private static ListNode reverseList2(ListNode head) &#123; ListNode result = null; ListNode t = head; ListNode preNode = null; while (t != null) &#123; ListNode nextNode = t.next; if (nextNode == null) &#123; result = t; &#125; t.next = preNode; preNode = t; t = nextNode; &#125; return result;&#125; 或者直接用Stack","categories":[],"tags":[{"name":"剑指Offer","slug":"剑指Offer","permalink":"https://hsb786.github.io/tags/剑指Offer/"}]},{"title":"链表中倒数第K个节点","slug":"链表中倒数第K个节点","date":"2018-04-10T12:13:03.000Z","updated":"2018-04-11T04:13:59.976Z","comments":true,"path":"2018/04/10/链表中倒数第K个节点/","link":"","permalink":"https://hsb786.github.io/2018/04/10/链表中倒数第K个节点/","excerpt":"输入一个链表，输出该链表的倒数第K个节点。为了符合大多数人的习惯，本题从1开始计数，即链表尾节点是倒数第一个节点。","text":"输入一个链表，输出该链表的倒数第K个节点。为了符合大多数人的习惯，本题从1开始计数，即链表尾节点是倒数第一个节点。12345678910111213141516171819202122232425 /** * 维护两个节点，后一个在前一个的后k位。 * 之后一起走，如果后一个节点为最后一个节点就停下 * @author: husb * @date: 2018年4月10日 下午7:29:09 */public static ListNode findKthNodeFromEnd(ListNode head, int k) &#123; ListNode node2 = head; int i = 1; if(k&lt;=0) &#123; System.out.println(&quot;必须从1开始&quot;); return null; &#125; while (i++ &lt; k) &#123; if (node2.next == null) &#123; return null; &#125; node2 = node2.next; &#125; while (node2.next != null) &#123; head = head.next; node2 = node2.next; &#125; return head;&#125;","categories":[],"tags":[{"name":"剑指Offer","slug":"剑指Offer","permalink":"https://hsb786.github.io/tags/剑指Offer/"}]},{"title":"调整数组顺序使奇数位于偶数之前","slug":"调整数组顺序使奇数位于偶数之前","date":"2018-04-10T12:10:37.000Z","updated":"2018-04-11T04:13:54.916Z","comments":true,"path":"2018/04/10/调整数组顺序使奇数位于偶数之前/","link":"","permalink":"https://hsb786.github.io/2018/04/10/调整数组顺序使奇数位于偶数之前/","excerpt":"输入一个整数数组，实现一个函数来调整该数组中数组的顺序，使得所有的奇数位于数组的前半部分，偶数位于数组的后半部分。","text":"输入一个整数数组，实现一个函数来调整该数组中数组的顺序，使得所有的奇数位于数组的前半部分，偶数位于数组的后半部分。 快速排序的思想 123456789101112131415161718192021 /** * 快速排序的思想 * 左边一个指针向右移，遇到偶数停止； * 右边一直指针向左移，遇到奇数停止。 * 两个值交换 * @author: husb * @date: 2018年4月10日 下午7:12:45 */private static void reorderOddEven(int[] arr) &#123; int left = -1; int right = arr.length ; while (left != right&amp;&amp;left&lt;=right) &#123; while(arr[++left]%2!=0&amp;&amp;left&lt;arr.length-1); while(arr[--right]%2==0&amp;&amp;right&gt;=0); if(left&lt;right) &#123; int t=arr[left]; arr[left]=arr[right]; arr[right]=t; &#125; &#125;&#125;","categories":[],"tags":[{"name":"剑指Offer","slug":"剑指Offer","permalink":"https://hsb786.github.io/tags/剑指Offer/"}]},{"title":"在O(1)时间内删除链表节点","slug":"在O(1)时间内删除链表节点","date":"2018-04-10T12:04:16.000Z","updated":"2018-04-11T04:13:49.998Z","comments":true,"path":"2018/04/10/在O(1)时间内删除链表节点/","link":"","permalink":"https://hsb786.github.io/2018/04/10/在O(1)时间内删除链表节点/","excerpt":"给定单向链表的头指针和一个节点指针，定义一个函数在O(1)时间删除该节点。","text":"给定单向链表的头指针和一个节点指针，定义一个函数在O(1)时间删除该节点。1234567891011121314151617181920212223 /** * 由于时间复杂度要求为O(1)， * 只能将加一个节点的值复制到要删除的节点，之后再将下一个节点删除 * @author: husb * @date: 2018年4月10日 下午3:43:23 */public static void deleteNode(ListNode head, ListNode node) &#123; //若为头节点，则将头节点设为head.next if (node == head) &#123; head = head.next; //若为未节点，只能遍历了 &#125; else if (node.next == null) &#123; ListNode t=head; while(t.next!=node) &#123; t=t.next; &#125; t.next=null; &#125; else &#123; //若为中间节点，则将下个节点的值复制到要删除的阶段，并且移除一个节点 node.data = node.next.data; node.next = node.next.next; &#125;&#125;","categories":[],"tags":[{"name":"剑指Offer","slug":"剑指Offer","permalink":"https://hsb786.github.io/tags/剑指Offer/"}]},{"title":"二进制中1的个数","slug":"二进制中1的个数","date":"2018-04-10T08:11:44.000Z","updated":"2018-04-11T04:13:44.093Z","comments":true,"path":"2018/04/10/二进制中1的个数/","link":"","permalink":"https://hsb786.github.io/2018/04/10/二进制中1的个数/","excerpt":"请实现一个函数，输入一个整数，输出该整数二进制表示中1的个数。","text":"请实现一个函数，输入一个整数，输出该整数二进制表示中1的个数。1234567891011121314/** * n&amp;(n-1)，将二进制表示中的最低位的1变为0 * @author: husb * @date: 2018年4月10日 下午3:23:02 */private static int numberOfOne(int n) &#123; int count=0; while(n!=0) &#123; n=n&amp;(n-1); count++; &#125; return count;&#125;","categories":[],"tags":[{"name":"剑指Offer","slug":"剑指Offer","permalink":"https://hsb786.github.io/tags/剑指Offer/"}]},{"title":"旋转数组的最小数字","slug":"旋转数组的最小数字","date":"2018-04-10T08:11:33.000Z","updated":"2018-04-11T04:13:39.073Z","comments":true,"path":"2018/04/10/旋转数组的最小数字/","link":"","permalink":"https://hsb786.github.io/2018/04/10/旋转数组的最小数字/","excerpt":"把一个数组最开始的若干个元素搬到数组的末尾，我们称之为数组的旋转。输入一个递增排序数组的一个旋转，输出旋转数组的最小元素。","text":"把一个数组最开始的若干个元素搬到数组的末尾，我们称之为数组的旋转。输入一个递增排序数组的一个旋转，输出旋转数组的最小元素。旋转数组的特点： 旋转之后的数组可以分为两个排序的子数组，且前面的子数组的元素都大于或等于后面子数组的元素。 最小或者最大元素位于两个子数组的分界 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657/** * 由于旋转数组的特点，前一个数组一定大于后一个数组。数组内部是升序的。 * 所以就可以使用二分查找。 * 定义minIndex为0，highIndex为length-1 * 若中间位大于array[minIndex]，则代表中间位处于前面部分,将minIndex设为midIndex； * 小于则处于后面部分,将highIndex设为midIndex * 最终minIndex位于前一个数组的最后一位，highIndex位于后一个数组的第一位 * 显然最小值就是highIndex所在的值。 * 特殊情况，但minIndex与highIndex上的值相等时，无法判断中间值是在前，还是在后。 * 所以只能用顺序查找 * @author: husb * @date: 2018年4月10日 下午2:56:26 */public static int findMin(int[] array) &#123; int lowIndex = 0; int highIndex = array.length - 1; int midIndex = (lowIndex + highIndex) / 2; // 当代查找数组第一位大于最后一位时，代表是旋转数组 while (array[lowIndex] &gt;= array[highIndex]) &#123; // 临界条件 前面最后一位，后面第一位。 后面第一位就是最小值 if (highIndex - lowIndex == 1) &#123; return array[highIndex]; &#125; // 当左下标的元素等于右下标的元素时，无法判断中间位是位于前面还是后面的。 // 只能用顺序查找 if (array[lowIndex] == array[highIndex]) &#123; return findMinInOrder(array, lowIndex, highIndex); &#125; // 当中间位大于前面第一位时，代表处于前面 if (array[midIndex] &gt; array[lowIndex]) &#123; lowIndex = midIndex; &#125; else &#123; // 否则处于后面 highIndex = midIndex; &#125; // 计算中间位 midIndex = (lowIndex + highIndex) / 2; &#125; //已排好序，返回低位即可 return array[lowIndex];&#125;/** * @Description: 当有重复元素的时候，无法确定中间的元素是前面的还是后面的 * @author: husb * @date: 2018年4月10日 下午2:33:52 */private static int findMinInOrder(int[] array, int lowIndex, int highIndex) &#123; int result = array[lowIndex]; for (int i = lowIndex + 1; i &lt;= highIndex; i++) &#123; if (result &gt; array[i]) &#123; result = array[i]; &#125; &#125; return result;&#125;","categories":[],"tags":[{"name":"剑指Offer","slug":"剑指Offer","permalink":"https://hsb786.github.io/tags/剑指Offer/"}]},{"title":"用两个队列实现一个栈","slug":"用两个队列实现一个栈","date":"2018-04-10T08:11:19.000Z","updated":"2018-04-11T04:14:11.737Z","comments":true,"path":"2018/04/10/用两个队列实现一个栈/","link":"","permalink":"https://hsb786.github.io/2018/04/10/用两个队列实现一个栈/","excerpt":"用两个队列实现一个栈","text":"用两个队列实现一个栈123456789101112131415161718192021222324252627282930313233343536373839404142/** * Queue方法: * offer() 添加一个元素，失败则返回false * pool() 移除并返回队列头部元素，无则返回null * peek() 返回头部元素 无则返回null */private static Queue&lt;Object&gt; queue1 = new LinkedList&lt;&gt;();private static Queue&lt;Object&gt; queue2 = new LinkedList&lt;&gt;();private static void push(Object obj) &#123; if (!queue1.isEmpty()) &#123; queue1.offer(obj); &#125; else &#123; queue2.offer(obj); &#125; System.out.println(&quot;入栈:&quot; + obj);&#125;/** * 将一个队列里的数据都剪切给另一个队列中，只保留最后一位。 * 这样弹出的数据就是栈尾数据 * @author: husb * @date: 2018年4月10日 下午1:55:11 */private static void pop() &#123; if (queue1.isEmpty() &amp;&amp; queue2.isEmpty()) &#123; System.out.println(&quot;栈里没有数据&quot;); return; &#125; if (queue1.isEmpty()) &#123; while (queue2.size() &gt; 1) &#123; queue1.offer(queue2.poll()); &#125; System.out.println(&quot;出栈:&quot; + queue2.poll()); return; &#125; while (queue1.size() &gt; 1) &#123; queue2.offer(queue1.poll()); &#125; System.out.println(&quot;出栈:&quot; + queue1.poll());&#125;","categories":[],"tags":[{"name":"剑指Offer","slug":"剑指Offer","permalink":"https://hsb786.github.io/tags/剑指Offer/"}]},{"title":"用两个栈实现队列","slug":"用两个栈实现队列","date":"2018-04-10T08:10:52.000Z","updated":"2018-04-11T04:13:33.773Z","comments":true,"path":"2018/04/10/用两个栈实现队列/","link":"","permalink":"https://hsb786.github.io/2018/04/10/用两个栈实现队列/","excerpt":"用两个栈实现一个队列。队列的声明如下：请实现他的两个函数appendTail和deleteHead,分别完成在队列尾部插入节点和在队列头部删除节点的功能。","text":"用两个栈实现一个队列。队列的声明如下：请实现他的两个函数appendTail和deleteHead,分别完成在队列尾部插入节点和在队列头部删除节点的功能。1234567891011121314151617181920212223242526272829private static Stack&lt;Object&gt; stack1 = new Stack&lt;Object&gt;();private static Stack&lt;Object&gt; stack2 = new Stack&lt;Object&gt;();/** * stack1用来存放压入的元素 * @author: husb * @date: 2018年4月10日 下午1:19:07 */public static void appendTail(Object item) &#123; stack1.push(item);&#125;public static void deleteHead() &#123; //当stack2中有数据，直接弹出 if (!stack2.isEmpty()) &#123; System.out.println(&quot;栈顶:&quot; + stack2.pop()); return; &#125; else &#123; //stack2压入stack1弹出的数据,这样stack2就是一个队列 while (!stack1.isEmpty()) &#123; stack2.push(stack1.pop()); &#125; &#125; if (!stack2.isEmpty()) &#123; System.out.println(&quot;栈顶:&quot; + stack2.pop()); &#125; else &#123; System.out.println(&quot;栈中没有元素&quot;); &#125;&#125;","categories":[],"tags":[{"name":"剑指Offer","slug":"剑指Offer","permalink":"https://hsb786.github.io/tags/剑指Offer/"}]},{"title":"替换空格","slug":"替换空格","date":"2018-04-10T08:08:27.000Z","updated":"2018-04-11T04:13:28.238Z","comments":true,"path":"2018/04/10/替换空格/","link":"","permalink":"https://hsb786.github.io/2018/04/10/替换空格/","excerpt":"请实现一个函数，将一个字符串中的空格替换成“%20”。","text":"请实现一个函数，将一个字符串中的空格替换成“%20”。例如，当字符串为We Are Happy.则经过替换之后的字符串We%20Are%20Happy。 1234567891011121314151617181920212223242526/** * beginIndex记录比较起始下标，spaceIndex记录空格下标。 * 添加beginIndex到spaceIndex的数据到StringBuilder中。 * beginIndex设为spaceIndex；spaceIndex重新计算 * @author: husb * @date: 2018年4月10日 下午12:26:55 */public static String replaceSpace(String str) &#123; //一开始想到的办法，一个字符一个字符的比， //这样会创建多个string对象,String.valueOf()内部是通过new String()来实现的。 /* * char[] chars = str.toCharArray(); StringBuilder sb = new StringBuilder(); for * (char c : chars) &#123; sb.append(c == &apos; &apos; ? &quot;%20&quot; : String.valueOf(c)); &#125; */ StringBuilder sb = new StringBuilder(); int beginIndex = 0; int spaceIndex = str.indexOf(&quot; &quot;, beginIndex); while (spaceIndex &gt; 0) &#123; sb.append(str.substring(beginIndex, spaceIndex)).append(&quot;%20&quot;); beginIndex = spaceIndex + 1; spaceIndex = str.indexOf(&quot; &quot;, beginIndex); &#125; sb.append(str.substring(beginIndex, str.length())); return sb.toString();&#125;","categories":[],"tags":[{"name":"剑指Offer","slug":"剑指Offer","permalink":"https://hsb786.github.io/tags/剑指Offer/"}]},{"title":"二维数组的查找","slug":"二维数组的查找","date":"2018-04-10T04:01:22.000Z","updated":"2018-04-11T04:13:19.198Z","comments":true,"path":"2018/04/10/二维数组的查找/","link":"","permalink":"https://hsb786.github.io/2018/04/10/二维数组的查找/","excerpt":"在一个二维数组中，每一行都按照从左到右递增的顺序排序，每一列都按照从上到下递增的顺序排序。请完成一个函数，输入这样的一个二维数组和一个整数，判断数组中是否含有该整数。","text":"在一个二维数组中，每一行都按照从左到右递增的顺序排序，每一列都按照从上到下递增的顺序排序。请完成一个函数，输入这样的一个二维数组和一个整数，判断数组中是否含有该整数。12345678910111213141516171819202122/** * 从左下角开始比，查找的数字大于遍历值右移；查找的数字小于遍历值上移 * @author: husb * @date: 2018年4月10日 上午11:55:27 */public static boolean find(int targer, int[][] array) &#123; int rows = array.length; int columns = array[0].length; int i = rows - 1, j = 0; while (targer != array[i][j]) &#123; if (targer &gt; array[i][j]) &#123; j++; &#125; else &#123; i--; &#125; if (i &lt; 0 || j &lt; 0 || i &gt; rows || j &gt; columns) &#123; return false; &#125; &#125; return true;&#125;","categories":[],"tags":[{"name":"剑指Offer","slug":"剑指Offer","permalink":"https://hsb786.github.io/tags/剑指Offer/"}]},{"title":"线程池","slug":"线程池","date":"2018-04-10T02:13:01.000Z","updated":"2018-04-11T08:07:27.842Z","comments":true,"path":"2018/04/10/线程池/","link":"","permalink":"https://hsb786.github.io/2018/04/10/线程池/","excerpt":"Executor框架Exexutor框架是一个根据一组执行策略调用，调度，执行和控制的异步任务的框架，可以用来控制线程的启动、执行和关闭，可以简化并发编程的操作。无限制的创建线程会引起应用程序内存溢出。所以创建一个线程池是个更好的解决方案，因为可以限制线程的数量并且可以回收再利用这些线程。Executor框架包括：线程池、Executor、Exexutors、ExecutorService、CompletionService、Future、Callable等。","text":"Executor框架Exexutor框架是一个根据一组执行策略调用，调度，执行和控制的异步任务的框架，可以用来控制线程的启动、执行和关闭，可以简化并发编程的操作。无限制的创建线程会引起应用程序内存溢出。所以创建一个线程池是个更好的解决方案，因为可以限制线程的数量并且可以回收再利用这些线程。Executor框架包括：线程池、Executor、Exexutors、ExecutorService、CompletionService、Future、Callable等。ExecutorService接口对Executor接口进行了扩展，提供了返回Future对象，终止，关闭线程池等方法。 通过ExecutorService.submit()方法返回的Future对象，还可以取消任务的执行。Future提供了Cancel()方法用来取消pending中的任务。 Executor是一个顶层接口，在它里面只声明了一个方法execute(Runnable)，返回值为void，参数为Runnable类型，从字面意思可以理解，就是用来执行传进去的任务的。然后ExecutorService接口继承了Executor接口，并声明了一些方法：submit、invokeAll、invokeAny以及shutDown等。抽象类AbstractExecutorService实现了ExecutorService接口，基本实现了ExecutorService中声明的所有方法。然后ThreadPoolExecutor继承了类AbstractExecutorService。 Executor ExecutorService Executor是java线程池的核心接口，用来并发执行提交的任务 ExecutorService是Executor接口的扩展，提供了异步执行和关闭线程的方法 提供execute()方法用来提交任务 提供submit方法用来提交任务 execute方法无返回值 submit方法返回Future对象 不能取消任务 Future.cancel()中断线程停止任务 没有提供和关闭线程池有关的方法 提供了关闭线程池的方法 关于Callable和Future Callable接口使用泛型去定义它的返回类型。Executors类提供了一些有用的方法去在线程池中执行Callable内的任务。由于Callable任务是并行的，我们必须等待它返回的结果。java.util.concurrent.Future对象为我们解决了这个问题。在线程池提交Callable任务后返回了一个Future对象，使用它我们可以知道Callable任务的状态和得到Callable返回的执行结果。Future提供了get()方法让我们可以等待Callable结束并获取它的执行结果。 Future提供了三种功能： 判断任务是否完成 能够中断任务 能够获取执行结果 关于Future中的cancel() Future对象提供了异步执行，这意味着无需等待任务执行的完成，只要提交需要执行的任务，然后再需要时检查Future是否已经有了结果，如果任务已经执行完成，就可以通过Future.get()方法获得执行结果。需要注意的是，Future.get()方法是一个阻塞式的方法，如果调用时任务还没有完成，会等待直到任务执行结束。 cancel()传入true时会中断线程停止任务，传入false则会让线程正常执行完成。 传入false只能取消还没有开始的任务，若任务已经开始了，就任由其运行下去。 FutureTask 123456789public class FutureTask&lt;V&gt; implements RunnableFuture&lt;V&gt; public interface RunnableFuture&lt;V&gt; extends Runnable, Future&lt;V&gt; &#123; /** * Sets this Future to the result of its computation * unless it has been cancelled. */ void run();&#125; FutureTask既可以做为Runnable被线程执行，又可以作为Future得到Callable的返回值 ThreadPoolExecutor 参数 说明 corePoolSize 线程池中核心线程数量 maximumPoolSize 线程池中最大线程数量 keepAliveTime 非核心线程存活时间 unit keepAliveTime的时间单位 workQueue 存放任务的队列 threadFactory 用来生产线程的工厂 handler 当线程池中不能再放入任务时执行的handler 任务提交给线程池之后的处理策略： 如果当前线程池中的线程数目小于corePoolSize，则每来一个任务，就会创建一个线程去执行这个任务； 如果当前线程池中的线程数目&gt;=corePoolSize，则每来一个认为，会尝试将其添加到任务缓存队列当中，若添加成功，则该任务会等待空闲线程将其取出来执行；若添加失败（一般来说是任务缓存队列已满），则会尝试创建新的线程去执行这个任务 如果当前线程池中的线程数目达到maximumPoolSize，则会采取任务拒绝策略进行处理； 如果线程池中的线程数量大于corePoolSize时，如果某线程空闲时间超过keepAliveTime，线程将被终止，直至线程池中的线程数目不大于corePoolSize；如果允许为核心池中的线程设置存活时间，那么核心池中的线程空闲时间超过KeepAliveTime，线程也会被终止 默认情况下，创建线程池之后，线程池中是没有线程的，需要提交任务之后才会创建线程。在实际中如果需要线程池创建之后立即创建线程，可以通过以下两个方法办到： prestartCoreThread()：初始化一个核心线程； prestartAllCoreThreads()：初始化所有核心线程 任务缓存队列及排队策略 workQueue，它用来存放等待执行的任务。workQueue的类型为BlockingQueue，通常可以取下面三种类型： ArrayBlockingQueue：基于数组的先进先出队列，此队列创建时必须指定大小 LinkedBlockingQueue：基于链表的先进先出队列，如果创建时没有指定此队列大小，则默认为Integer.MAX_VALUE synchronousQueue：这个队列比较特殊，它不会保存提交的任务，而是将直接新建一个线程来执行新来的任务 参考 Java并发编程：线程池的使用 Java多线程之Callable接口及线程池","categories":[],"tags":[{"name":"爪哇","slug":"爪哇","permalink":"https://hsb786.github.io/tags/爪哇/"}]},{"title":"java基础总结","slug":"java基础总结","date":"2018-04-09T13:28:54.000Z","updated":"2018-04-11T04:17:39.893Z","comments":true,"path":"2018/04/09/java基础总结/","link":"","permalink":"https://hsb786.github.io/2018/04/09/java基础总结/","excerpt":"初始化顺序 父类（静态变量，静态语句块） 子类（静态变量，静态语句块） 父类（实例变量，普通语句块） 父类（构造函数） 子类（实例变量，普通语句块） 子类（构造函数）","text":"初始化顺序 父类（静态变量，静态语句块） 子类（静态变量，静态语句块） 父类（实例变量，普通语句块） 父类（构造函数） 子类（实例变量，普通语句块） 子类（构造函数） Object 123456789101112131415161718192021public final native Class&lt;?&gt; getClass()public native int hashCode()public boolean equals(Object obj)protected native Object clone() throws CloneNotSupportedExceptionpublic String toString()public final native void notify()public final native void notifyAll()public final native void wait(long timeout) throws InterruptedExceptionpublic final void wait(long timeout, int nanos) throws InterruptedExceptionpublic final void wait() throws InterruptedExceptionprotected void finalize() throws Throwable &#123;&#125; 异常 Throwable可以用来表示任何可以作为异常抛出的类，分为两种：Error和Exception。其中Error用来表示JVM无法处理的错误，Exception分为两种： 受检异常（checked exception）：需要try…catch…语句捕获并进行处理，并且可以从一场恢复 非受检异常（unchecked exception）：是程序运行时错误，例如除0会引发Arithmetic Exceptino，此时程序崩溃并且无法恢复","categories":[],"tags":[{"name":"爪哇","slug":"爪哇","permalink":"https://hsb786.github.io/tags/爪哇/"}]},{"title":"需要注意的一些东西","slug":"需要注意的一些东西","date":"2018-04-09T05:53:41.000Z","updated":"2018-04-11T04:27:39.572Z","comments":true,"path":"2018/04/09/需要注意的一些东西/","link":"","permalink":"https://hsb786.github.io/2018/04/09/需要注意的一些东西/","excerpt":"happens-before 在JMM中，如果一个操作执行的结果需要对另一个操作可见，那么这两个操作之间必须要存在happens-before关系 需要注意的是，上面提到的两个操作可以是在不同线程之间的，而且并不意味着前一个操作必须要在后一个操作之前执行，仅仅要求前一个操作的执行结果对后一个操作可见","text":"happens-before 在JMM中，如果一个操作执行的结果需要对另一个操作可见，那么这两个操作之间必须要存在happens-before关系 需要注意的是，上面提到的两个操作可以是在不同线程之间的，而且并不意味着前一个操作必须要在后一个操作之前执行，仅仅要求前一个操作的执行结果对后一个操作可见 happends-before规则 程序顺序规则： 单个线程中的每个操作，happens-before于该线程中的任意后续操作 监视器锁规则： 对一个锁的解锁，happens-before于随后对这个锁的加锁 volatile变量规则： 对一个volatile变量的写，happends-before于任意后续对这个volatile变量的读 传递性： 如果A happeens-before B，且 B happeend-before C，那么A happeens-before C join规则： 如果线程A执行操作ThreadB.join()成功返回，那么线程B中的任意操作happeens-before与线程A从ThreadB.join()操作成功返回 fail-fast fail-fast机制是java集合(Collection)中的一种错误机制。当多个线程对同一集合的内容进行操作时，就可能会产生fail-fast事件。 例如：当某一个线程A通过iterator去遍历某集合的过程中，若该集合的内容被其他线程所改变了；那么线程A访问集合时，就会抛出ConcurrentModificationException异常，产生fail-fast事件 要了解fail-fast机制，我们首先要对ConcurrentModificationException 异常有所了解。当方法检测到对象的并发修改，但不允许这种修改时就抛出该异常。同时需要注意的是，该异常不会始终指出对象已经由不同线程并发修改，如果单线程违反了规则，同样也有可能会抛出改异常。诚然，迭代器的快速失败行为无法得到保证，它不能保证一定会出现该错误，但是快速失败操作会尽最大努力抛出ConcurrentModificationException异常 当使用fail-fast iterator对Collection或对Map进行操作过程中尝试直接修改Collection/Map的内容时，即使是在单线程下运行，java.util.ConcurrentModificationException异常也将抛出 Iterator是工作在一个独立的线程，并且拥有一个mutex锁。Iterator被创建之后会建立一个指向原来对象的单链索引表，当原来对象发生变化时，这个索引表的内容不会同步该表，所以当索引指针往后移动的时候就找不到要迭代的对象，所以按照fail-fast原则Iterator会马上抛出ConsurrentModificationException异常。 所以Iterator在工作的时候是不允许被迭代的对象被改变的。但你可以使用Iterator本身的方法remove()来删除对象，Iteraror.remove()方法会在删除当前迭代对象的同时维护索引的一致性。 Streams 引入的原因 声明性方式处理数据集合 透明的进行处理，提高性能 流与集合 集合与流的差异就在于什么时候进行计算 集合是内存中的数据结构，包含数据结构中目前所有的值 流的元素则是按需计算/生存 遍历数据的方式 集合使用Collection接口，需要用户去做迭代，称为外部迭代 流的Streams库使用内部迭代 流的使用 一个数据源（如集合）来执行一个查询 一个中间操作链，形成一条流的流水线 一个终端操作，执行流水线，并能生产结果 流的操作类型 Intermediate : 一个流后面跟随零个或多个intermediate操作。其目的主要是打开流，做出某种程度的数据映射/过滤，然后返回一个新的流，交给下一个操作使用。这类操作都是惰性化的，也就是说，仅仅调用到这类方法，并没有真正开始流的遍历 Terminal ： 一个流只能有一个terminal操作，当这个操作执行后，流就被使用“光”了，无法再被操作。所以这必定是流的最后一根操作。terminal操作的执行，才会真正开始流的变量 数据库三大范式 1NF：字段不可再分 2NF：主键依赖，一张表里的数据，必须是跟主键相关的 3NF：任意两个表不能出现重复的非主键字段 设计模式六大原则 单一职责(Single Responsibility Principle)：一个类只负责一个功能领域中的相应职责 开闭(Open-Closed Principle)：对扩展开放，对修改关闭 里氏替换(Liskov Subsitution Principle)：子类能出现在基类出现的地方 依赖倒置(Dependency Inversion Principle)：针对接口编程，而不是针对实现类编程 接口隔离(Interface Segregation Principle)：使用多个专门的接口，而不使用单一的总接口 迪米特(Law of Demeter)：一个类尽可能少的与其它类发生相互作用","categories":[],"tags":[{"name":"爪哇","slug":"爪哇","permalink":"https://hsb786.github.io/tags/爪哇/"}]},{"title":"记录一些容易忘记的东西","slug":"记录一些容易忘记的东西","date":"2018-04-09T00:42:41.000Z","updated":"2018-04-11T04:19:52.611Z","comments":true,"path":"2018/04/09/记录一些容易忘记的东西/","link":"","permalink":"https://hsb786.github.io/2018/04/09/记录一些容易忘记的东西/","excerpt":"接口不可以实现接口，可以继承多个接口 抽象类可以继承具体类 static不能被重写，重写是运行时动态绑定的 static变量发生在静态解析阶段，此时已经将字段的符号引用转换成了内存引用，将它与对应的类关联在了一起","text":"接口不可以实现接口，可以继承多个接口 抽象类可以继承具体类 static不能被重写，重写是运行时动态绑定的 static变量发生在静态解析阶段，此时已经将字段的符号引用转换成了内存引用，将它与对应的类关联在了一起子类构造方法默认会寻找父类无参构造方法，若没有，编译不通过 抽象方法必须为public否则protected，缺省情况下默认为public java8中接口可以含有default方法和static方法 volatile 禁止指令重排序： 添加内存屏障，保证前面已经完成，后面都没开始 内部类访问外部类 外部类.this.成员XX 重载静态绑定，根据参数的静态类型而不是实际类型作为判断依据的 java的8中基本类型，除了float和double之外，其它6种都实现了常量池 boolean类型不允许进行任何类型的转换处理 java7以后，常量池被放入到堆空间中。导致Intern()函数的功能不同。intern()检查常量池时候存在该字符串，存在的话就直接返回；否则返回首次在堆中声明的相同字符串的引用 ArrayList 默认容器 10 HashMap 16 newInstance 低效率，只能调用无参构造。将new这个方式分解为两步： 首先调用class的加载方式加载某个类，然后实例化 HashSet底层借用HashMap private static final Object PRESENT=new Object();123public boolean add(E e) &#123; return map.put(e, PRESENT)==null;&#125; 字符只有在内存中才会形成，其它都是以字节的方式进行的 强引用： Object obj=new Object()，只要引用还在，就不会被回收软引用： 内存不够才会被回收弱引用： 下一次垃圾收集器工作时会被回收。虚引用： 随时可能被回收，目的是能在这个对象被回收时收到一个系统通知 内加载器： JVM动态加载所需的类。 委托、可见、单一。交给父加载器；父加载器加载的类子加载器都能看到；一个类只能被一个加载一次 每个对象有两个队列： 就绪队列、阻塞队列 ReentrantLock结合Condition可以有选择性地进行通知，在调度上更加灵活 指令重排序： 编译器和处理器为了优化程序性能而对指令序列进行重新排序的一种手段 null可以强制转换为任何java类类型其返回值还是null，可以调用static方法","categories":[],"tags":[{"name":"爪哇","slug":"爪哇","permalink":"https://hsb786.github.io/tags/爪哇/"}]},{"title":"区别","slug":"区别","date":"2018-04-08T23:48:41.000Z","updated":"2018-04-11T06:11:17.363Z","comments":true,"path":"2018/04/09/区别/","link":"","permalink":"https://hsb786.github.io/2018/04/09/区别/","excerpt":"sleep和wait区别 sleep是Thread类的static方法； wait是Object类的方法 sleep()睡眠时保持对象锁； wait释放锁 sleep可以放在任何地方； wait()必须放在synchronized block中，否则会在runtime是扔出IllegalMonitorStateExcetion异常","text":"sleep和wait区别 sleep是Thread类的static方法； wait是Object类的方法 sleep()睡眠时保持对象锁； wait释放锁 sleep可以放在任何地方； wait()必须放在synchronized block中，否则会在runtime是扔出IllegalMonitorStateExcetion异常 synchronized和volatile区别 volatile是线程同步的轻量级实现，性能比synchronized好 volatile只能修饰变量； synchronized可修饰方法和代码块 volatile能保证数据可见性，不保证原子性； synchronized可以保证原子性，也可以间接保证可见性。synchronized会将私有内存和公共内存中的数据进行同步 volatile解决的是变量在多个线程间的可见性； synchronized解决的是多个线程访问资源的同步性 内部类 在类中定义一个类(私有内部类，静态内部类)在方法中定义一个类(局部内部类，匿名内部类) 私有内部类编译器做的手脚 在内部类中创建了包可见构造器，从而使外部类获得了创建权限 在外部类中创建了访问私有变量的静态方法，从而使内部类获得了范围权限 静态内部类只能访问其外部类的静态成员 局部内部类没有修饰符，局部内部类只能范围该方法中的局部变量，并且这些局部变量一定要是final修饰的产量或者隐含是final的(java8) 匿名内部类不能抽象；仅能被使用一次；不能存在静态成员变量和方法只有静态内部类可以访问静态成员变量 Session和Cookie的区别 Session是在服务端保存的一个数据结构，用来跟踪用户的状态，这个数据可以保存在集群、数据库、文件中。 Cookie是客户端保存用户信息的一种机制，用来记录用户的一些信息，也是实现Session的一种方式。 客户端传JSESSIONID，服务端就可以通过这个ID，来将存储到服务端的数据取出 Servlet和Filter的区别 Filter对用户请求进行预处理，接着将请求交给Servlet进行处理并生成响应，最后Filter再对响应的数据进行后处理。 强、软、弱、虚引用 强引用 Object obj=new Object()，只要引用还在，就不会被回收软引用内存不够才会被回收弱引用下一次垃圾收集器工作时会被回收。虚引用随时可能被回收，目的是能在这个对象被回收时收到一个系统通知。垃圾回收期是一个优先级较低的线程，并不一定能迅速发现弱引用对象 HashMap和Hashtable的区别 先吐槽一下Hashtable的命名，为啥t要小写 Hashtable是线程安全的； HashMap不是 Hashtable不允许有null的KV； HashMap运行 Hashtable继承Dictionary类； HashMap继承AbstractMap HashMap有一个子类LinkedHashMap，对这个类对象进行迭代时，它的顺序是有序的。可以轻易的将LinkedHashMap转换成HashMap； Hashtable不好实现 相同点：都实现了Map接口 join和sleep的区别 join底层调用wait方法，执行到wait释放锁sleep在睡眠时不释放锁 JDK动态代理和CGLIB代理的区别 JDK动态动态代理是利用反射机制生存一个实现代理接口的匿名类，在调用具体方法前调用InvokeHandler来处理。JDK动态代理只能对实现了接口的类生成代理，而不能针对类 CGLIB动态代理是利用ASM开源包，将目标对象类的class文件加载进来，通过修改其字节码生成子类来处理。CGLIB是针对类实现代理，主要是对指定的类生成一个子类，覆盖其中的方法。 JDK动态代理是面向接口的，在创建代理实现类时比CGLIB要快，创建代理速度快。CGLIB动态代理是通过字节码底层继承要代理类的目标类来实现，创建速度没有JDK动态代理快，但是运行速度比JDK动态代理快。 重载和重写的区别 重载： 方法有同样的名称，但是参数列表不同 重写：在java的子类与父类中有两个名称、参数列表都相同的方法的情况。由于它们具有相同的方法签名，所以子类中的新方法将覆盖父类中原有的方法 区别 重载 重写 编译期概念，遵循“编译期绑定”，即在编译时根据参数变量的类型判断应该调用哪个方法 运行期概念，遵循“运行期绑定”，即在运行的时候，根据引用变量所指向的实际对象的类型来调用方法 方法签名必须不同 方法签名必须一样 返回类型可以不同 返回类型必须相同 无限制 更好的访问，不能抛出更广泛的异常（遵循里式替换原则） 组合与继承的区别和联系 在继承结构中，父类的内部细节对于子类是可见的。所以我们通常也可以说通过继承的代码复用是一种白盒式代码复用。（如果基类的实现发生改变，那么派生类的实现也将随之改变。这样就导致了子类行为的不可预知性；) 组合是通过对现有的对象进行拼装（组合）产生新的、更复杂的功能。因为在对象之间，各自的内部细节是不可见的，所以我们也说这种方式的代码复用是黑盒式代码复用。（因为组合中一般都定义一个类型，所以在编译期根本不知道具体会调用哪个实现类的方法） 继承，在写代码的时候就要指名具体继承哪个类，所以，在编译期就确定了关系。（从基类继承来的实现是无法在运行期动态改变的，因此降低了应用的灵活性。） 组合，在写代码的时候可以采用面向接口编程。所以，类的组合关系一般在运行期确定。 优缺点对比 组 合 关 系 继 承 关 系 优点：不破坏封装，整体类与局部类之间松耦合，彼此相对独立 缺点：破坏封装，子类与父类之间紧密耦合，子类依赖于父类的实现，子类缺乏独立性 优点：具有较好的可扩展性 缺点：支持扩展，但是往往以增加系统结构的复杂度为代价 优点：支持动态组合。在运行时，整体对象可以选择不同类型的局部对象 缺点：不支持动态继承。在运行时，子类无法选择不同的父类 优点：整体类可以对局部类进行包装，封装局部类的接口，提供新的接口 缺点：子类不能改变父类的接口 缺点：整体类不能自动获得和局部类同样的接口 优点：子类能自动继承父类的接口 缺点：创建整体类的对象时，需要创建所有局部类的对象 优点：创建子类的对象时，无须创建父类的对象 如何选择 继承要慎用，其使用场合仅限于你确信使用该技术有效的情况。一个判断方法是，问一问自己是否需要从新类向基类进行向上转型。如果是必须的，则继承是必要的。反之则应该好好考虑是否需要继承。&lt;&lt;java编程思想&gt;&gt; 只有当子类真正是超类的子类型时，才适合用继承。换句话说，对于两个类A和B，只有当两者之间确实存在is-a关系的时候，类B才应该继承类A。&lt;&gt; Compareable和Comparator Comparable：一个实现了Comparable接口的类，可以让其自身的对象和其它对象进行比较。也就是说，同一个类的对象之间要想比较，对应的类就要实现Compareable接口，并实现compareTo()方法。 Comparator：不改变原有的类。通过定义一个类实现Comparator接口，重写compare()方法。 Comparator通常用于排序。Java中的Collectinos和Arrays都包括排序的sort方法，该方法可以接受一个Comparator的实例(比较器)来进行排序；new TreeSet&lt;&gt;(new Comparator())","categories":[],"tags":[{"name":"爪哇","slug":"爪哇","permalink":"https://hsb786.github.io/tags/爪哇/"}]},{"title":"hash","slug":"hash","date":"2018-04-08T13:23:41.000Z","updated":"2018-04-10T10:10:41.840Z","comments":true,"path":"2018/04/08/hash/","link":"","permalink":"https://hsb786.github.io/2018/04/08/hash/","excerpt":"","text":"哈希 Hash，一般翻译成“散列”，也有直接音译为“哈希”的，就是把任意长度的输入，通过散列算法，变换成固定长度的输出，该输出就是散列值 特性：根据同一散列函数计算出的散列值如果不同，那么输入值肯定也不同。但是，根据同一散列函数计算出的散列值如果相同，输入值不一定相同 两个不同的输入值，根据同一散列函数计算出的散列值相同的现象叫做碰撞","categories":[],"tags":[{"name":"爪哇","slug":"爪哇","permalink":"https://hsb786.github.io/tags/爪哇/"}]},{"title":"一些小技巧","slug":"一些小技巧","date":"2018-04-08T09:58:41.000Z","updated":"2018-04-11T04:42:45.628Z","comments":true,"path":"2018/04/08/一些小技巧/","link":"","permalink":"https://hsb786.github.io/2018/04/08/一些小技巧/","excerpt":"位运算直接对内存数据进行操作，不需要转成十进制，因此处理速度非常快 X % 2^n = X &amp; (2^n-1)","text":"位运算直接对内存数据进行操作，不需要转成十进制，因此处理速度非常快 X % 2^n = X &amp; (2^n-1) 判段一个数组是否包含某个值12Set&lt;String&gt; set=new HashSet&lt;String&gt;(Arrays.asList(arr)); return set.contains(targetValue); 效率慢，要将数组压入Collection类型中，首先要将数组元素便利一遍，然后再使用集合类做其它操作。 可以使用Apache Commons类库中提供的ArrayUtils类的contains方法contains内部调用indexOf方法","categories":[],"tags":[{"name":"爪哇","slug":"爪哇","permalink":"https://hsb786.github.io/tags/爪哇/"}]},{"title":"防止重复发送 Ajax 请求的解决方案","slug":"防止重复发送 Ajax 请求的解决方案","date":"2018-04-08T09:58:41.000Z","updated":"2018-04-11T04:20:05.795Z","comments":true,"path":"2018/04/08/防止重复发送 Ajax 请求的解决方案/","link":"","permalink":"https://hsb786.github.io/2018/04/08/防止重复发送 Ajax 请求的解决方案/","excerpt":"连续点击多个按钮，可能导致先请求的数据后显示出来。 解决方案 1. 将ajsx请求的async设置为false 2. 利用jquery ajaxPrefilter中断请求","text":"连续点击多个按钮，可能导致先请求的数据后显示出来。 解决方案 1. 将ajsx请求的async设置为false 2. 利用jquery ajaxPrefilter中断请求12345678910111213141516171819var pendingRequests = &#123;&#125;;$.ajaxPrefilter(function( options, originalOptions, jqXHR ) &#123; var key = options.url; console.log(key); if (!pendingRequests[key]) &#123; pendingRequests[key] = jqXHR; &#125;else&#123; //jqXHR.abort(); //放弃后触发的提交 pendingRequests[key].abort(); // 放弃先触发的提交 &#125; var complete = options.complete; options.complete = function(jqXHR, textStatus) &#123; pendingRequests[key] = null; if ($.isFunction(complete)) &#123; complete.apply(this, arguments); &#125; &#125;;&#125;); 核心思想是维护一个队列，发送请求时，将请求加入队列，请求响应后，从队列中清楚，这就保证了在任一时刻只能有一个同样的请求发送 局限性：仅对jquery的ajax有作用 参考 http://www.hollischuang.com/archives/931","categories":[],"tags":[{"name":"前端","slug":"前端","permalink":"https://hsb786.github.io/tags/前端/"}]},{"title":"事务","slug":"事务","date":"2018-04-08T09:58:41.000Z","updated":"2018-04-11T04:21:36.957Z","comments":true,"path":"2018/04/08/事务/","link":"","permalink":"https://hsb786.github.io/2018/04/08/事务/","excerpt":"事务（Transaction），一般是指要做的或所做的事情。在计算机术语中是指访问并可能更新数据库中各种数据项的一个程序执行单元（unit）。在计算机术语中，事务通常就是指数据库事务。","text":"事务（Transaction），一般是指要做的或所做的事情。在计算机术语中是指访问并可能更新数据库中各种数据项的一个程序执行单元（unit）。在计算机术语中，事务通常就是指数据库事务。概念 一个数据库事务通常包含对数据库进行读或写的一个操作序列。它的存在包括有以下两个目的 为数据库提供了一个从失败中恢复到正常状态的方法，同时提供了数据库即使在异常状态下仍能保持一致性的方法。 当多个应用程序在并发访问数据库时，可以在这些应用程序之间提供一个隔离的方法，以防止彼此的操作互相干扰。 当一个事务被提交给了DBMS（数据库管理系统），则DBMS需要确保该事务中的所有操作都成功完成且其结果被永久保存在数据库中，如果事务中有的操作没有成功完成，则事务中的所有操作都需要被回滚，回到事务执行前的状态（要么全执行，要么全都不执行）;同时，该事务对数据库或者其他事务的执行无影响，所有的事务都好像在独立的运行。 但在现实情况下，失败的风险很高。在一个数据库事务的执行过程中，有可能会遇上事务操作失败、数据库系统/操作系统失败，甚至是存储介质失败等情况。这便需要DBMS对一个执行失败的事务执行恢复操作，将其数据库状态恢复到一致状态（数据的一致性得到保证的状态）。为了实现将数据库状态恢复到一致状态的功能，DBMS通常需要维护事务日志以追踪事务中所有影响数据库数据的操作。 特性 并非任意的对数据库的操作序列都是数据库事务。事务应该具有4个属性：原子性、一致性、隔离性、持久性。这四个属性通常称为ACID特性。 原子性（Atomicity）：事务作为一个整体被执行，包含在其中的对数据库的操作要么全部被执行，要么都不执行。一致性（Consistency）：事务应确保数据库的状态从一个一致状态转变为另一个一致状态。一致状态的含义是数据库中的数据应满足完整性约束。隔离性（Isolation）：多个事务并发执行时，一个事务的执行不应影响其他事务的执行。持久性（Durability）：一个事务一旦提交，他对数据库的修改应该永久保存在数据库中。 脏读：又称无效数据的读出。指一个事务对数据进行了修改，还没有提交到数据库中，另外一个事务访问并使用了该数据。由于这个数据还没有提交，所以另外一个事务读到的这个数据是脏数据。 不可重复读：一个事务范围内对两个相同的查询却返回了不同数据。这是因为其它事务修改的提交而引起的。 幻读：指当事务不是独立执行时发生的一种现象。例如第一个事务涉及到表中全部数据行的修改，另一个事务添加了一行新数据，那么执行第一个事务后，发现表中还有没有被修改的数据行。 隔离级别 未提交读(Read uncommitted)：一个事务可以读取另一个事务未提交的数据 提交读(Read committed)：在一个事务修改数据过程中，其它事务不能读该数据 数据库锁情况 事务对当前读取的数据加行级共享锁（当读到时才加锁），一旦读完该行，立即释放该行级共享锁 事务在更新某数据的瞬间（就是发生更新的瞬间），必须先对其加行级排他锁，直到事务结束才释放。 可重复读(Repeatable reads)：解决不可重复读的问题 数据库锁情况 事务在读取某数据的瞬间，必须先对其加行级共享锁，直到事务结束才释放 事务在更新某数据的瞬间，必须先对其加行级排他锁，直到事务结束才释放 序列化(Serializable)：最高的隔离级别 数据库锁情况 事务在读取数据时，必须先对其加表级共享锁，直到事务结束才释放 事务在更新数据时，必须先对其加表级排他锁，直到事务结束才释放 隔离级别越高，同时在并发现上也越低 锁的分类 按锁级别划分： 共享锁(Share Lock) 又称读锁，是读取操作创建的锁。其它用户可以并发读取数据，但任何事务都不能对数据进行修改，直到已释放所有共享锁 如果事务T对数据A加上共享锁后，则其它事务只能对A再加共享锁，不能加排他锁。获取共享锁的事务只能读数据，不能修改数据 用法 select … LOCK IN SHARE MODE， 当没有其它线程对查询结果集中的任何一行使用排他锁时，可以成功申请共享锁，否则会被阻塞。其它线程也可以读取使用了共享锁的表，而且这些线程读取的是同一个版本的数据 排他锁(eXclusive Lock) 又称写锁，如果事务T对数据A加上排他锁后，则其他事务不能再对A加任何类型的锁。获取排他锁的事务既能读数据，又能修改数据 用法 select … FOR UPDATE 当没有其它线程对查询结果集中的任何一行使用排他锁时，可以成功申请排他锁，否则会被阻塞 按锁的粒度划分 行级锁 对当前操作的行进行加锁。加锁粒度最小，但加锁的开销最大。行级锁分为共享锁和排他锁 特点 开销大，加锁慢；会出现死锁；锁定力度最小，发生锁冲突的概率最低，并发度也最高。 表级锁 对当前操作的整张表加锁，它实现简单，资源消耗较少，被大部分MySQL引擎支持。最常使用的MYISAM与INNODB都支持表级锁定。表级锁定分为表共享读锁（共享锁）与表独占写锁（排他锁）。 特点 开销小，加锁快；不会出现死锁；锁定粒度大，发出锁冲突的概率最高，并发度最低。 页级锁 页级锁是MySQL中锁定粒度介于行级锁和表级锁中间的一种锁。表级锁速度快，但冲突多，行级冲突少，但速度慢。所以取了折衷的页级，一次锁定相邻的一组记录。BDB支持页级锁 特点 开销和加锁时间界于表锁和行锁之间；会出现死锁；锁定粒度界于表锁和行锁之间，并发度一般 Innodb中的行锁与表锁 InnoDB行锁是通过给索引上的索引项加锁来实现的。InnoDB这种行锁实现特点意味着：只有通过索引条件检索数据，InnoDB才使用行级锁，否则，InnoDB将使用表锁！ 行级锁与死锁 在MySQL中，行级锁并不是直接锁记录，而是锁索引。索引分为主键索引和非主键索引两种，如果一条sql语句操作了主键索引，MySQL就会锁定这条主键索引；如果一条语句操作了非主键索引，MySQL会先锁定该非主键索引，再锁定相关的主键索引。 在UPDATE、DELETE操作时，MySQL不仅锁定WHERE条件扫描过的所有索引记录，而且会锁定相邻的键值，即所谓的next-key locking。 当两个事务同时执行，一个锁住了主键索引，在等待其他相关索引。另一个锁定了非主键索引，在等待主键索引。这样就会发生死锁。 发生死锁后，InnoDB一般都可以检测到，并使一个事务释放锁回退，另一个获取锁完成事务。 常见的三种解决死锁的方法 如果不同程序会并发存取多个表，尽量约定以相同的顺序访问表，可以大大降低死锁机会 在同一个事务中，尽可能做到一次锁定所需要的所有资源，减少死锁产生概率 对于非常容易产生死锁的业务部分，可以尝试使用升级锁定颗粒度，通过表级锁定来减少死锁产生的概率 按使用方式划分 悲观锁 在关系数据库管理系统里，悲观并发控制（又名“悲观锁”，Pessimistic Concurrency Control，缩写“PCC”）是一种并发控制的方法。它可以阻止一个事务以影响其他用户的方式来修改数据。如果一个事务执行的操作都某行数据应用了锁，那只有当这个事务把锁释放，其他事务才能够执行与该锁冲突的操作。 悲观并发控制主要用于数据争用激烈的环境，以及发生并发冲突时使用锁保护数据的成本要低于回滚事务的成本的环境中。 在数据库中，悲观锁的流程如下： 在对任意记录进行修改前，先尝试为该记录加上排他锁（exclusive locking）。 如果加锁失败，说明该记录正在被修改，那么当前查询可能要等待或者抛出异常。 具体响应方式由开发者根据实际需要决定。 如果成功加锁，那么就可以对记录做修改，事务完成后就会解锁了。 其间如果有其他对该记录做修改或加排他锁的操作，都会等待我们解锁或直接抛出异常。 使用select…for update会把数据给锁住，不过我们需要注意一些锁的级别，MySQL InnoDB默认行级锁。行级锁都是基于索引的，如果一条SQL语句用不到索引是不会使用行级锁的，会使用表级锁把整张表锁住，这点需要注意。 优点与不足 悲观并发控制实际上是“先取锁再访问”的保守策略，为数据处理的安全提供了保证。但是在效率方面，处理加锁的机制会让数据库产生额外的开销，还有增加产生死锁的机会；另外，在只读型事务处理中由于不会产生冲突，也没必要使用锁，这样做只能增加系统负载；还有会降低了并行性，一个事务如果锁定了某行数据，其他事务就必须等待该事务处理完才可以处理那行数 乐观锁 在关系数据库管理系统里，乐观并发控制（又名“乐观锁”，Optimistic Concurrency Control，缩写“OCC”）是一种并发控制的方法。它假设多用户并发的事务在处理时不会彼此互相影响，各事务能够在不产生锁的情况下处理各自影响的那部分数据。在提交数据更新之前，每个事务会先检查在该事务读取数据后，有没有其他事务又修改了该数据。如果其他事务有更新的话，正在提交的事务会进行回滚。乐观事务控制最早是由孔祥重（H.T.Kung）教授提出。 乐观锁（ Optimistic Locking ） 相对悲观锁而言，乐观锁假设认为数据一般情况下不会造成冲突，所以在数据进行提交更新的时候，才会正式对数据的冲突与否进行检测，如果发现冲突了，则让返回用户错误的信息，让用户决定如何去做。 相对于悲观锁，在对数据库进行处理的时候，乐观锁并不会使用数据库提供的锁机制。一般的实现乐观锁的方式就是记录数据版本。 数据版本,为数据增加的一个版本标识。当读取数据时，将版本标识的值一同读出，数据每更新一次，同时对版本标识进行更新。当我们提交更新的时候，判断数据库表对应记录的当前版本信息与第一次取出来的版本标识进行比对，如果数据库表当前版本号与第一次取出来的版本标识值相等，则予以更新，否则认为是过期数据。 优点与不足 乐观并发控制相信事务之间的数据竞争(data race)的概率是比较小的，因此尽可能直接做下去，直到提交的时候才去锁定，所以不会产生任何锁和死锁。但如果直接简单这么做，还是有可能会遇到不可预期的结果，例如两个事务都读取了数据库的某一行，经过修改以后写回数据库，这时就遇到了问题。","categories":[],"tags":[{"name":"sql","slug":"sql","permalink":"https://hsb786.github.io/tags/sql/"}]},{"title":"值传递和引用传递","slug":"值传递和引用传递","date":"2018-04-08T09:58:41.000Z","updated":"2018-04-11T04:18:58.946Z","comments":true,"path":"2018/04/08/值传递和引用传递/","link":"","permalink":"https://hsb786.github.io/2018/04/08/值传递和引用传递/","excerpt":"值传递 指在调用函数时将实际参数复制一份传递到函数中，那么在函数中对参数所进行的修改，将不会影响到实际参数。 引用传递 指在调用函数时将实际参数的地址直接传递到函数中，那么在函数中对参数所进行的修改，将影响到实际参数。","text":"值传递 指在调用函数时将实际参数复制一份传递到函数中，那么在函数中对参数所进行的修改，将不会影响到实际参数。 引用传递 指在调用函数时将实际参数的地址直接传递到函数中，那么在函数中对参数所进行的修改，将影响到实际参数。求值策略 | 求值时间 | 求值方式 | 根本区别—|—|—-|—值传递 | 调用前 | 值的结果（原值的副本）| 会创建副本引用传递 | 调用前 | 原值（原始对象，无副本）| 不创建副本 值传递和引用传递的区别并不是传递的内容，而是实参到底有没有被复制一份到形参 java只有值传递，不存在引用传递 java在传递引用类型数据时，把实际参数的内存地址复制了一份，传递给了形参","categories":[],"tags":[{"name":"爪哇","slug":"爪哇","permalink":"https://hsb786.github.io/tags/爪哇/"}]},{"title":"Spring整理","slug":"Spring整理","date":"2018-04-08T09:58:41.000Z","updated":"2018-04-11T04:21:37.911Z","comments":true,"path":"2018/04/08/Spring整理/","link":"","permalink":"https://hsb786.github.io/2018/04/08/Spring整理/","excerpt":"Spring结构Spring框架的核心组件只有三个：Bean，Context，Core Spring是面向Bean编程，自然Bean组件就是Spring对Java对象Object的封装，在Spring容器中管理的就是被Bean封装了的Java对象。Bean组件解决了Bean的定义，Bean的创建以及Bean的解析。 Context组件就是我们常说的IOC容器，也就是Spring容器。Context组件可以发现每个Bean之间的关系，为它们建立好Bean之间的依赖关系，为Bean提供生存环境。 Core组件，它是Context组件与Bean组件的工具包，可以把Core组件理解为Util工具包","text":"Spring结构Spring框架的核心组件只有三个：Bean，Context，Core Spring是面向Bean编程，自然Bean组件就是Spring对Java对象Object的封装，在Spring容器中管理的就是被Bean封装了的Java对象。Bean组件解决了Bean的定义，Bean的创建以及Bean的解析。 Context组件就是我们常说的IOC容器，也就是Spring容器。Context组件可以发现每个Bean之间的关系，为它们建立好Bean之间的依赖关系，为Bean提供生存环境。 Core组件，它是Context组件与Bean组件的工具包，可以把Core组件理解为Util工具包 Spring容器Spring容器有时候也称为IOC容器。IOC: Inverse of Control，控制反转。控制：控制就是调用类对某一个接口具体实现类的选择控制权反转：选择控制权交给第三方决定，由Spring容器来统一配置管理Bean。 为了更好理解IOC，大家经常使用依赖注入来代替控制反转这个概念，即让调用类对某一接口的实现类的依赖关系由第三方容器注入，以移除调用类对某一接口实现类的依赖。那么IOC容器的工作就是通过配置文件和注解来描述类和类之间的依赖关系。利用反射机制完成类的初始化和依赖注入。 BeanFactory和ApplicationContextBeanFactory是Spring框架核心接口，提供了IOC的配置机制，是Spring的基础设施，面向Spring本身 ApplicationContext是建立在BeanFactory之上，提供了更多的面向应用的功能，是Spring给开发者提高了IOC容器接口 参考 https://lujunqiu.github.io/2018/02/01/Spring容器——面向Bean编程/","categories":[],"tags":[{"name":"Spring","slug":"Spring","permalink":"https://hsb786.github.io/tags/Spring/"}]},{"title":"SpringMVC","slug":"SpringMVC","date":"2018-04-08T09:58:41.000Z","updated":"2018-04-11T04:13:00.200Z","comments":true,"path":"2018/04/08/SpringMVC/","link":"","permalink":"https://hsb786.github.io/2018/04/08/SpringMVC/","excerpt":"SpringMVC工作流程SpringMVC是一种基于Servelt的技术，它提供了控制器DispatchServlet和相关组件，这些SpringMVC的组件一起协调工作，完成对web请求的相应。","text":"SpringMVC工作流程SpringMVC是一种基于Servelt的技术，它提供了控制器DispatchServlet和相关组件，这些SpringMVC的组件一起协调工作，完成对web请求的相应。 客户端发出一个HTTP请求，Web服务器接收到这个请求。服务器检查HTTP请求的路径，如果匹配DispatchServelt的请求映射路径(web.xml中指定)，则Web容器将该请求转交给对应的DispatchServlet处理 DispatchServlet接收到这个请求后，将根据请求的信息以及HandlerMapping配置找到处理请求的处理器（Handler）。HandlerMapping可以简单理解为统一资源标识符URL域与处理器Handler之间的关系。 找到对应的处理器之后，通过HandlerAdapter对Handler进行封装，再以同一的适配器接口调用Handler。因为为了更加灵活的编码和AOP增强功能，SpringMVC会给处理器加入拦截器，这样就可以在处理器执行前后加入执行前后加入自己的代码，于是就构成了一个处理器的执行链，所以SpringMVC提供了处理器适配器HandlerAdapter，帮助我们运行相应的处理器以及我们添加进去的拦截器。 处理器完成了请求的业务逻辑之后将返回一个ModelAndView对象给DIspatcherServlet，这里ModelAndView包含了视图的逻辑名和模型数据信息。 得到了ModelAndView之后，DispatchServlet借助ViewResolver视图解析器将逻辑试图转换为真实视图。 通过ViewResolver视图解析器得到了真实视图后，DispatServlet使用这个真实视图对象对ModelAndView中的模型数据进行渲染。 最终DispatchServlet将渲染过后的视图对象返回给请求的客户端，客户端得到的响应可能是一个普通的HTML页面，也可能是一个JSON串，甚至是一张图片等等不同的视图模型。 另一个说法 DispatcherServlet是什么它是Spring MVC的核心。每个由Spring MVC处理的请求都要经过DispatcherServlet。一般而言，它是前端控制器模式的实现，为应用提供一个统一入口。DispatcherServlet是连接Java与Spring的桥梁，处理所有传入的请求。并且与其他声明在web.xml中的Servlet一样，也是通过一个URL pattern将每个请求映射到DispatcherServlet。DispatcherServlet负责将请求委派给Spring MVC中其他的组建处理，比如注有@Controller或@RestController的Controller类，HandlerMappers（处理映射），View Resolvers(视图解析器)等等。 尽管，请求映射是由 @ResquestMapping 注解完成的，但实际上是由 DispatcherServlet 将请求委派给相应的 Controller 来处理的。 DispatcherServlet如何处理请求正如上面所说，DispatcherServlet 被用来处理所有传入的请求，并将它们路由到不同的 Controller 来进行进一步处理。它决定了由哪个 Controller 处理请求。 DispatcherServlet 使用处理器映射来将传入的请求路由到处理器。默认情况下，使用 BeanNameUrlHandlerMapping 和 由 @RequestMapping 注解驱动的DefaultAnnotationHandlerMapping。 为了找到正确的方法来处理请求，它会扫描所有声明了 @Controller 注解的类，并且通过 @RequestMapping 注解找到负责处理该请求的方法。@RequestMapping 注解可以通过路径来映射请求(比如: @RequestMapping(“path”)), 也可以通过 HTTP 方法(比如: @RequestMapping(“path”, method=RequestMethod.GET)), 也可以通过请求参数(比如: @RequestMapping(“path””, method=RequestMethod.POST, params=”param1”)),还可以通过 HTTP 请求头(比如: @RequestMapping(“path”, header=”content-type=text/*”))。我们也可以在类级别声明 @RequestMapping 注解来过滤传入的请求。 在请求处理之后，Controller 会将逻辑视图的名字和 model 返回给 DispatcherServlet。之后利用视图解析器定位到真正的 View 以便渲染结果。我们可以指定使用的视图解析器，默认情况下，DispatcherServlet 使用 InternalResourceViewResolver来将逻辑视图的名字转换成真正的视图，比如 JSP。 选定视图之后，DispatcherServlet 会将数据模型与视图相结合，并将结果返回给客户端。并不是任何时候都需要视图，比如一个 RESTful 的 web 服务就不需要，它们的处理方法会利用 @ResponseBody 注解直接将请求结果返回给客户端。可以看REST with Spring course了解更多关于如何使用 Spring MVC 开发和测试 RESTful 服务的知识。 参考 https://lujunqiu.github.io/2018/01/17/Spring-MVC框架入门/ https://yemengying.com/2017/10/07/spring-dispatcherServlet/","categories":[],"tags":[{"name":"Spring","slug":"Spring","permalink":"https://hsb786.github.io/tags/Spring/"}]},{"title":"Java虚拟机是如何执行线程同步的","slug":"Java虚拟机是如何执行线程同步的","date":"2018-04-08T09:48:41.000Z","updated":"2018-04-12T03:55:58.142Z","comments":true,"path":"2018/04/08/Java虚拟机是如何执行线程同步的/","link":"","permalink":"https://hsb786.github.io/2018/04/08/Java虚拟机是如何执行线程同步的/","excerpt":"线程和共享数据 在JVM中，每个线程独享一块栈内存，其中包括局部变量、线程调用的每个方法的参数和返回值。其它线程无法读取到该栈内存块中的数据。栈中的数据仅限于基本类型和对象引用。 在JVM中，堆内存是所有线程共享的。对象在堆中。 还有一部分数据保存JVM中的方法区中，比如类的静态变量。方法去和栈类似，其中只包含基本类型和对象引用。和栈不同的是，方法区中的静态变量可以被所有线程访问到。","text":"线程和共享数据 在JVM中，每个线程独享一块栈内存，其中包括局部变量、线程调用的每个方法的参数和返回值。其它线程无法读取到该栈内存块中的数据。栈中的数据仅限于基本类型和对象引用。 在JVM中，堆内存是所有线程共享的。对象在堆中。 还有一部分数据保存JVM中的方法区中，比如类的静态变量。方法去和栈类似，其中只包含基本类型和对象引用。和栈不同的是，方法区中的静态变量可以被所有线程访问到。 对象和类的锁 JMM中有两块区域可以被所有线程共享 堆，存放着所有对象方法区，存放着静态变量 那么，如果有多个线程想要同时访问同一个对象或者静态变量，就需要被管控，否则可能出现不可预期的结果 为了协调多个线程之间的共享数据访问，虚拟机给每个对象和类都分配了一个锁。这个锁就像一个特权，在同一时刻，只有一个线程可以“拥有”这个类或者对象。如果一个线程想要获得某个类或者对象的锁，需要询问虚拟机。当一个线程向虚拟机申请某个类或者对象的锁之后，也许很快或者很慢虚拟机可以把锁分配给这个线程，同时这个线程也许永远也无法获得锁。但线程不再需要锁的时候，他再把锁还给虚拟机。这时虚拟机就可以再把锁分配给其它申请锁的线程。 类锁其实通过对象锁实现的。因为当虚拟机加载一个类的时候，会为这个类实例化一个java.lang.Class对象，当你锁住一个类的时候，其实锁住的是其对应的Class对象 监视器（Monitors） 锁其实是通过监视器实现的，监视器主要功能是监控一段代码，确保在同一时间只有一个线程在执行。 每个监视器都与一个对象相关联。当线程执行到监视器监视下的代码块中的第一条指令时，线程必须获取对被引用对象的锁定。在线程获取锁之前，它是无法执行这段代码的，一旦获得锁，线程便可以进入“被保护”的代码开始执行。 当线程离开代码块时，无论如何离开，都会释放所关联对象的锁 多次加锁 同一个线程可以对同一个对象进行多次加锁。每个对象维护着一个记录着被锁次数的计数器。未被锁定的对象的该计数器为0，当一个线程获得锁喉，该计数器自增变为1，当同一个线程再次获得该对象的锁的时候，计数器再次自增。当同一个线程释放锁的时候，计数器再自减。当计数器为0的时候。锁将被释放，其它线程便可以获得锁。 同步 在Java中，当有多个线程都必须要对同一个共享数据进行访问时，有一种协调方式叫做同步。Java语言提供了两种内置方式来使线程同步的访问数据：同步代码块和同步方法。 *参考 [Java Java虚拟机是如何执行线程同步的 ]http://www.hollischuang.com/archives/1876)","categories":[],"tags":[{"name":"爪哇","slug":"爪哇","permalink":"https://hsb786.github.io/tags/爪哇/"}]},{"title":"lombok","slug":"lombok","date":"2018-04-08T08:23:41.000Z","updated":"2018-04-11T04:46:26.649Z","comments":true,"path":"2018/04/08/lombok/","link":"","permalink":"https://hsb786.github.io/2018/04/08/lombok/","excerpt":"通过使用@Data注解自动帮你生成getters,setters,toString(),equals(),hashCode()方法 @AllArgsConstructor 全参构造函数 @NoArgsConstructor 无参构造函数","text":"通过使用@Data注解自动帮你生成getters,setters,toString(),equals(),hashCode()方法 @AllArgsConstructor 全参构造函数 @NoArgsConstructor 无参构造函数","categories":[],"tags":[{"name":"工具","slug":"工具","permalink":"https://hsb786.github.io/tags/工具/"}]},{"title":"NaN","slug":"NaN","date":"2018-04-08T08:07:41.000Z","updated":"2018-04-10T10:11:08.451Z","comments":true,"path":"2018/04/08/NaN/","link":"","permalink":"https://hsb786.github.io/2018/04/08/NaN/","excerpt":"","text":"NaN表示未定义或不可表示的指 A constant holding a Not-a-Number (NaN) value of type public static final double NaN = 0.0d /0.0; Java中的Double和Float都有isNaN。判断一个数是不是NaN，通过v!=v的方式。 NaN是唯一与自己不相等的指，NaN与任何值都不相等。","categories":[],"tags":[{"name":"爪哇","slug":"爪哇","permalink":"https://hsb786.github.io/tags/爪哇/"}]},{"title":"VSCode快捷键","slug":"VSCode快捷键","date":"2018-04-08T07:58:41.000Z","updated":"2018-04-11T04:12:21.261Z","comments":true,"path":"2018/04/08/VSCode快捷键/","link":"","permalink":"https://hsb786.github.io/2018/04/08/VSCode快捷键/","excerpt":"","text":"ctrl B 侧边栏显/隐ctrl shift E 资源管理器ctrl tab 文件切换F1或ctrl shift p 命令窗口","categories":[],"tags":[{"name":"工具","slug":"工具","permalink":"https://hsb786.github.io/tags/工具/"}]},{"title":"git命令","slug":"gitCommand","date":"2018-04-08T07:42:41.000Z","updated":"2018-04-10T10:10:37.686Z","comments":true,"path":"2018/04/08/gitCommand/","link":"","permalink":"https://hsb786.github.io/2018/04/08/gitCommand/","excerpt":"","text":"","categories":[],"tags":[{"name":"工具","slug":"工具","permalink":"https://hsb786.github.io/tags/工具/"}]},{"title":"markdown","slug":"markdown","date":"2018-04-08T04:31:41.000Z","updated":"2018-04-11T04:47:58.818Z","comments":true,"path":"2018/04/08/markdown/","link":"","permalink":"https://hsb786.github.io/2018/04/08/markdown/","excerpt":"Markdown结合VSCode来使用斜体删除线","text":"Markdown结合VSCode来使用斜体删除线 分割 baidu 引用 演示列表 列表还可以有层级 第一章1.1节有序列表 wfe fwef 表格 header1 header 2 row 1 col 1 哈哈 换行 row 2 col 1 哈哈 我的邮箱：&#x37;&#x38;&#x36;&#x33;&#x39;&#56;&#55;&#57;&#56;&#x40;&#113;&#113;&#x2e;&#x63;&#111;&#x6d; 1代码块","categories":[],"tags":[{"name":"工具","slug":"工具","permalink":"https://hsb786.github.io/tags/工具/"}]}]}